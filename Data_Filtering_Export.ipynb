{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACLED Data Processing Pipeline for Conflict Event Extraction\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook presents a data processing pipeline developed for transforming raw ACLED (Armed Conflict Location & Event Data) records into structured datasets suitable for machine learning applications. The work focuses specifically on conflict events occurring across Eastern Europe, Central Europe, and the Baltic States, with particular emphasis on modern warfare patterns including the ongoing Ukraine-Russia conflict.\n",
    "\n",
    "**Primary objective**: To develop and validate a robust field extraction system capable of parsing unstructured conflict reports into fourteen structured data fields, creating a high-quality training dataset for fine-tuning small language models on Apple Silicon hardware using MLX.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "### Data Scope and Geographic Focus\n",
    "\n",
    "The pipeline processes ACLED records from thirteen European countries, creating a regionally coherent dataset that captures modern conflict dynamics across:\n",
    "\n",
    "- **Eastern Europe**: Ukraine, Russia, Belarus, Moldova, Bulgaria, Romania\n",
    "- **Central Europe**: Poland, Czech Republic, Hungary, Slovakia  \n",
    "- **Baltic States**: Lithuania, Latvia, Estonia\n",
    "\n",
    "This geographic constraint ensures consistency whilst concentrating analysis on regions experiencing significant security developments, particularly in the context of interstate conflict and cross-border operations.\n",
    "\n",
    "### Technical Implementation\n",
    "\n",
    "#### Quality Assessment Framework\n",
    "\n",
    "A ten-point scoring system specifically calibrated for conflict event data, evaluating:\n",
    "\n",
    "- Structural indicators (temporal markers, geographic references, actor identification)\n",
    "- Information density (casualty figures, weapon specifications, infrastructure details)\n",
    "- Content coherence (sourcing, date precision, event specificity)\n",
    "\n",
    "#### Advanced Field Extraction System\n",
    "\n",
    "The core extraction module employs pattern recognition to identify:\n",
    "\n",
    "- **Temporal and geographic intelligence**: Multi-format date parsing and cross-border operation handling\n",
    "- **Actor detection**: Ten-tier hierarchical system covering military forces, protest groups, and security services\n",
    "- **Modern weapons recognition**: Contemporary systems including FPV drones, Shahed drones, HIMARS, and calibre-specific artillery\n",
    "- **Infrastructure impact assessment**: Eight critical categories from power grid disruption to military installations\n",
    "\n",
    "#### Cross-Border Intelligence\n",
    "\n",
    "Special handling for interstate operations, including:\n",
    "\n",
    "- Automatic attribution of Belgorod region events to Russia\n",
    "- Detection of Ukrainian strikes on Russian territory and vice versa\n",
    "- Proper classification of cross-border military operations as interstate conflict\n",
    "\n",
    "### Validation and Quality Assurance\n",
    "\n",
    "Multi-stage validation ensures data integrity through:\n",
    "\n",
    "- Field completeness verification across all fourteen target fields\n",
    "- Geographic and actor consistency checks\n",
    "- Numeric range validation for casualty figures\n",
    "- Content quality thresholds preventing low-information samples from proceeding\n",
    "\n",
    "## Results and Performance\n",
    "\n",
    "### Test Suite Validation\n",
    "\n",
    "Comprehensive testing across six diverse conflict scenarios achieved:\n",
    "\n",
    "- **100% individual field accuracy** across 40 specific tests\n",
    "- **100% complete case success** (6/6 test cases fully passed)\n",
    "- **100% validation success** with robust error handling\n",
    "\n",
    "### Processing Outcomes\n",
    "\n",
    "From an initial dataset of 309.974 ACLED records:\n",
    "\n",
    "- **Quality filtering**: Retained records meeting structural and content thresholds\n",
    "- **Field extraction**: Successfully processed samples with comprehensive field coverage\n",
    "- **Strategic selection**: Created a curated subset optimised for machine learning applications\n",
    "\n",
    "### Geographic Coverage\n",
    "\n",
    "The system demonstrates reliable country detection across all thirteen target nations, with particular strength in handling complex conflict scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Dependencies\n",
    "\n",
    "The following libraries were used to support data preparation, model training, and evaluation:\n",
    "\n",
    "- **`pandas`** – For structured data manipulation and export of ACLED subsets.\n",
    "- **`re`** – For regular expression-based field extraction and pattern matching.\n",
    "- **`json`** – To handle input/output in JSONL format for model training and testing.\n",
    "- **`os`** – For managing file paths and workspace structure.\n",
    "- **`random`** – For consistent dataset sampling and shuffling.\n",
    "- **`unicodedata`** – To standardise and normalise Unicode characters.\n",
    "- **`datetime`** – For timestamping and log generation.\n",
    "- **`defaultdict`** – To aggregate prediction statistics for evaluation.\n",
    "\n",
    "These tools enabled efficient handling of the ACLED dataset and structured evaluation of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully. Environment is ready for data processing and export.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "print(\"Libraries imported successfully. Environment is ready for data processing and export.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geographic Filtering and Data Loading\n",
    "\n",
    "This section implements the primary data ingestion and regional filtering operations, applying systematic geographic constraints to ensure analytical coherence and focus on contemporary European security dynamics.\n",
    "\n",
    "### Target Geographic Scope\n",
    "\n",
    "The pipeline processes ACLED records exclusively from thirteen carefully selected European nations, creating a regionally coherent dataset optimised for modern conflict analysis:\n",
    "\n",
    "**Eastern Europe**\n",
    "- **Ukraine** — 243.794 records (78.6%) — Primary focus given ongoing interstate conflict\n",
    "- **Russia** — 39.280 records (12.7%) — Essential for cross-border operations analysis\n",
    "- **Belarus** — 4.085 records — Regional security dynamics\n",
    "- **Moldova** — 2.013 records — Including Transnistrian separatist activities\n",
    "- **Bulgaria** — 4.430 records — Southeastern European stability\n",
    "- **Romania** — 3.101 records — NATO frontier dynamics\n",
    "\n",
    "**Central Europe**\n",
    "- **Poland** — 8.231 records — Critical NATO ally and Ukrainian support hub\n",
    "- **Czech Republic** — 1.509 records — Central European stability patterns\n",
    "- **Hungary** — 1.273 records — Regional political developments\n",
    "- **Slovakia** — 1.046 records — Visegrad Group dynamics\n",
    "\n",
    "**Baltic States**\n",
    "- **Lithuania** — 517 records — Russian border security concerns\n",
    "- **Latvia** — 291 records — Ethnic minority dynamics\n",
    "- **Estonia** — 404 records — Digital warfare and hybrid threats\n",
    "\n",
    "### Data Processing Results\n",
    "\n",
    "The geographic filtering yields a comprehensive dataset spanning multiple conflict types and temporal periods:\n",
    "\n",
    "- **Total dataset scope**: 309.974 conflict-event records from the ACLED database\n",
    "- **Temporal coverage**: Multi-year span capturing evolving security patterns from traditional protests to modern interstate warfare\n",
    "- **Data integrity**: 100% retention of records containing substantive textual notes suitable for downstream natural language processing\n",
    "\n",
    "### Field Extraction Targets\n",
    "\n",
    "The pipeline extracts fourteen structured fields designed to capture the essential dimensions of contemporary conflict events:\n",
    "\n",
    "**Core identifiers**: `event_date`, `country`, `location`, `event_type`\n",
    "\n",
    "**Actor analysis**: `actor_1`, `actor_2`\n",
    "\n",
    "**Impact assessment**: `fatalities`, `civilian_casualties`, `property_damage`\n",
    "\n",
    "**Technical intelligence**: `weapons_mentioned`, `casualty_type`, `attack_method`\n",
    "\n",
    "**Strategic analysis**: `disorder_type`, `infrastructure_disruption`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising ACLED data loading and filtering process\n",
      "Target country count: 13\n",
      "Target fields count: 14\n",
      "\n",
      "Export directory: ACLED_data_export\n",
      "Loaded 527,211 total records.\n",
      "Filtered to 309,974 records from target countries.\n",
      "Retained 309,974 records with non-null notes.\n",
      "\n",
      "Country distribution:\n",
      "  Ukraine            243,794 ( 78.6%)\n",
      "  Russia             39,280 ( 12.7%)\n",
      "  Poland              8,231 (  2.7%)\n",
      "  Bulgaria            4,430 (  1.4%)\n",
      "  Belarus             4,085 (  1.3%)\n",
      "  Romania             3,101 (  1.0%)\n",
      "  Moldova             2,013 (  0.6%)\n",
      "  Czech Republic      1,509 (  0.5%)\n",
      "  Hungary             1,273 (  0.4%)\n",
      "  Slovakia            1,046 (  0.3%)\n",
      "  Lithuania             517 (  0.2%)\n",
      "  Estonia               404 (  0.1%)\n",
      "  Latvia                291 (  0.1%)\n",
      "\n",
      "Date range: 2018-01-01 to 2025-07-04\n",
      "\n",
      "Dataset ready: 309,974 records from 13 countries.\n"
     ]
    }
   ],
   "source": [
    "TARGET_COUNTRIES = [\n",
    "    \"Ukraine\", \"Russia\", \"Belarus\", \"Moldova\", \"Bulgaria\", \"Romania\",\n",
    "    \"Poland\", \"Czech Republic\", \"Hungary\", \"Slovakia\",                  \n",
    "    \"Lithuania\", \"Latvia\", \"Estonia\"                                    \n",
    "]\n",
    "\n",
    "# Define TARGET_FIELDS consistently, especially if planned to add more fields in the future\n",
    "TARGET_FIELDS = [\n",
    "    'event_date', 'country', 'location', 'event_type',\n",
    "    'actor_1', 'actor_2', 'fatalities', 'civilian_casualties',\n",
    "    'property_damage', 'weapons_mentioned', 'casualty_type', 'attack_method',\n",
    "    'disorder_type', 'infrastructure_disruption'\n",
    "]\n",
    "\n",
    "print(\"Initialising ACLED data loading and filtering process\")\n",
    "print(f\"Target country count: {len(TARGET_COUNTRIES)}\")\n",
    "print(f\"Target fields count: {len(TARGET_FIELDS)}\\n\")\n",
    "\n",
    "export_dir = \"ACLED_data_export\"\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "print(f\"Export directory: {export_dir}\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(\"Europe-Central-Asia_2018-2025_July.csv\", low_memory=False)\n",
    "    print(f\"Loaded {len(df):,} total records.\")\n",
    "\n",
    "    df = df[df[\"country\"].isin(TARGET_COUNTRIES)].copy()\n",
    "    print(f\"Filtered to {len(df):,} records from target countries.\")\n",
    "\n",
    "    # Remove entries without notes\n",
    "    df = df[df[\"notes\"].notna()].copy()\n",
    "    print(f\"Retained {len(df):,} records with non-null notes.\")\n",
    "\n",
    "    # Parse event dates\n",
    "    df[\"event_date\"] = pd.to_datetime(df[\"event_date\"])\n",
    "\n",
    "    print(\"\\nCountry distribution:\")\n",
    "    for country, count in df[\"country\"].value_counts().items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"  {country:<18} {count:>6,} ({pct:>5.1f}%)\")\n",
    "\n",
    "    print(f\"\\nDate range: {df['event_date'].min().date()} to {df['event_date'].max().date()}\")\n",
    "    data_source = \"ACLED\"\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"ACLED dataset not found. Initialising fallback: synthetic dataset.\\n\")\n",
    "\n",
    "    # Synthetic fallback for testing or development\n",
    "    synthetic_data = []\n",
    "    for i in range(2000):\n",
    "        country = TARGET_COUNTRIES[i % len(TARGET_COUNTRIES)]\n",
    "        date = f\"2024-{(i % 12) + 1:02d}-{(i % 28) + 1:02d}\"\n",
    "        note = (\n",
    "            f\"On {date}, government forces responded to a security incident in {country}. \"\n",
    "            f\"Local authorities confirmed the situation was under control.\"\n",
    "        )\n",
    "        synthetic_data.append({\n",
    "            \"notes\": note,\n",
    "            \"country\": country,\n",
    "            \"event_date\": date\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(synthetic_data)\n",
    "    df[\"event_date\"] = pd.to_datetime(df[\"event_date\"])\n",
    "    print(f\"Created synthetic dataset with {len(df):,} records.\")\n",
    "    data_source = \"synthetic\"\n",
    "\n",
    "print(f\"\\nDataset ready: {len(df):,} records from {df['country'].nunique()} countries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Assessment of Conflict Notes\n",
    "\n",
    "Each ACLED note undergoes an extensive quality assessment using a ten-point scoring system specifically calibrated for conflict-event data. The assessment ensures that linguistically and semantically adequate records proceed to field extraction, maintaining maximum dataset coverage.\n",
    "\n",
    "### Assessment Criteria\n",
    "\n",
    "**Structural Validation**\n",
    "\n",
    "- **Minimum length**: At least 50 characters with substantial content\n",
    "- **Readability**: Plain-text encoding without formatting errors\n",
    "- **Content structure**: Presence of structural indicators (*on*, *at*, *in*, *during*, *according*, *reported*)\n",
    "\n",
    "**Information-Density Scoring**\n",
    "\n",
    "- **Temporal precision**: Full-date formats (e.g. \"19 April 2025\") receive maximum points\n",
    "- **Geographic specificity**: Multiple location mentions and regional identifiers\n",
    "- **Actor attribution**: Military, police, or protest-group identification\n",
    "- **Event details**: Casualty numbers, damage reports, and weapon specifications\n",
    "\n",
    "#### Scoring System (0–10 Scale)\n",
    "\n",
    "- **Length scoring (0–3 points)**: Progressive scoring from 50 to 400+ characters\n",
    "- **Content quality (0–3 points)**: Bonus for precise dates, sourcing, and casualty figures\n",
    "- **Information density (0–4 points)**: Geographic diversity, actor specificity, and event-detail richness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_note_quality(text):\n",
    "    \"\"\"\n",
    "    Quality assessment with realistic scoring criteria for ACLED data.\n",
    "    Returns (passes_threshold, quality_score) where quality_score is 0-10.\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return False, 0.0\n",
    "\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return False, 0.0\n",
    "        \n",
    "    text_lower = text.lower()\n",
    "\n",
    "    # Structural validation for ACLED data\n",
    "    checks = {\n",
    "        \"sufficient_length\": len(text) >= 50,\n",
    "        \"has_content\": bool(text and text != \"\"),\n",
    "        \"readable\": not bool(re.search(r\"[^\\x00-\\x7F]{20,}\", text)),  # More lenient\n",
    "        \"has_structure\": bool(re.search(r\"\\b(on|at|in|during|according|reported|confirmed)\\b\", text_lower)),  \n",
    "        \"has_location\": bool(re.search(r\"\\b[A-Z][a-z]{2,}\\b\", text)),  # Shorter names are allowed\n",
    "        \"has_actors\": bool(re.search(r\"\\b(forces|police|military|troops|protesters|rebels|government)\\b\", text_lower)),\n",
    "        \"has_temporal\": bool(re.search(r\"\\b(january|february|march|april|may|june|july|august|september|october|november|december|\\d{1,2}/\\d{1,2}/\\d{4})\\b\", text_lower)),\n",
    "        \"has_numbers\": bool(re.search(r\"\\b\\d+\\b\", text)),\n",
    "        \"has_action\": bool(re.search(r\"\\b(attack|fired|killed|injured|protest|clash|explosion|reported)\\b\", text_lower))\n",
    "    }\n",
    "\n",
    "    # Require at least 4 checks to pass\n",
    "    passes_basic = sum(checks.values()) >= 4\n",
    "\n",
    "    # Scoring system (0-10 scale)\n",
    "    score = 0.0\n",
    "\n",
    "    # Length scoring (0-3 points)\n",
    "    if len(text) >= 400:\n",
    "        score += 3.0\n",
    "    elif len(text) >= 200:\n",
    "        score += 2.5\n",
    "    elif len(text) >= 100:\n",
    "        score += 2.0\n",
    "    elif len(text) >= 50:\n",
    "        score += 1.5\n",
    "\n",
    "    # Content quality (0-3 points)\n",
    "    if re.search(r\"\\b\\d{1,2}\\s+(January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{4}\\b\", text):\n",
    "        score += 1.0\n",
    "    if re.search(r\"\\b(according to|reported|confirmed by|sources said)\\b\", text_lower):\n",
    "        score += 1.0\n",
    "    if re.search(r\"\\b\\d+\\s+(killed|dead|injured|wounded|casualties)\\b\", text_lower):\n",
    "        score += 1.0\n",
    "\n",
    "    # Geographic and actor specificity (0-2 points)\n",
    "    location_matches = re.findall(r\"\\b[A-Z][a-z]{2,}\\b\", text)\n",
    "    location_count = len(set(location_matches)) if location_matches else 0\n",
    "    if location_count >= 2:\n",
    "        score += 1.0\n",
    "    elif location_count >= 1:\n",
    "        score += 0.5\n",
    "\n",
    "    actor_keywords = [\"forces\", \"police\", \"military\", \"troops\", \"protesters\", \"government\", \"officials\"]\n",
    "    actor_count = sum(1 for word in actor_keywords if word in text_lower)\n",
    "    if actor_count >= 2:\n",
    "        score += 1.0\n",
    "    elif actor_count >= 1:\n",
    "        score += 0.5\n",
    "\n",
    "    # Information density (0-2 points)\n",
    "    event_indicators = [\"attack\", \"bombing\", \"shooting\", \"protest\", \"clash\", \"strike\", \"explosion\", \"fired\"]\n",
    "    event_count = sum(1 for term in event_indicators if term in text_lower)\n",
    "    if event_count >= 2:\n",
    "        score += 1.0\n",
    "    elif event_count >= 1:\n",
    "        score += 0.5\n",
    "\n",
    "    detail_indicators = [\"casualties\", \"damage\", \"weapons\", \"injuries\", \"arrested\", \"hospital\", \"school\"]\n",
    "    detail_count = sum(1 for indicator in detail_indicators if indicator in text_lower)\n",
    "    if detail_count >= 2:\n",
    "        score += 1.0\n",
    "    elif detail_count >= 1:\n",
    "        score += 0.5\n",
    "\n",
    "    return passes_basic, min(score, 10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Field Extraction System\n",
    "\n",
    "This module transforms unstructured ACLED conflict reports into fourteen structured fields through sophisticated pattern recognition, contextual analysis, and robust error handling specifically calibrated for contemporary Eastern European conflict scenarios.\n",
    "\n",
    "### Core Extraction Capabilities\n",
    "\n",
    "#### Temporal and Geographic Intelligence\n",
    "\n",
    "- **Multi-format date recognition**: Processes eight distinct date patterns including European formats (`15 March 2024`), contextual phrases (`On 19 April 2025`), and numeric variations (`15/03/2024`, `2024-03-15`)\n",
    "- **Cross-border operation handling**: Correctly attributes events across national boundaries (e.g., Ukrainian strikes in Belgorod → Russia)\n",
    "- **Advanced location extraction**: Six-tier pattern system detecting cities, regions, and facilities whilst filtering 60+ false positives\n",
    "- **Geographic context preservation**: Maintains accuracy for complex scenarios like \"Russian forces operating on Ukrainian soil\"\n",
    "\n",
    "#### Country Detection with Cross-Border Intelligence\n",
    "\n",
    "- **Highest priority**: Belgorod and Russian border regions (Kursk, Bryansk, Voronezh, Rostov) automatically attributed to Russia\n",
    "- **Cross-border operations**: \"Ukrainian drones struck Belgorod region\" correctly attributed to Russia as event location\n",
    "- **Three-tier system**: Border regions → cross-border patterns → standard country detection\n",
    "- **Comprehensive coverage**: Thirteen target countries with region-specific patterns and city identification\n",
    "\n",
    "#### Hierarchical Actor Detection System\n",
    "\n",
    "- **Ten-tier primary actor recognition**: From action-context patterns (\"Ukrainian forces launched\") to generic fallbacks\n",
    "- **Twelve-tier secondary actor targeting**: Identifies forces under attack through targeting patterns and casualty analysis\n",
    "- **Specific unit types**: Territorial defence, marines, national guard, air forces, partisans, and militia groups\n",
    "- **Protest actors**: Demonstrators, activists, opposition groups, trade unions, and civil society\n",
    "- **Regional military forces**: All thirteen countries covered with specific force identification\n",
    "\n",
    "#### Modern Weapons and Equipment Recognition\n",
    "\n",
    "- **Contemporary systems**: FPV drones, Shahed drones, HIMARS, Iskander-M missiles, FAB aerial bombs, Lancet drones\n",
    "- **Calibre-specific detection**: 120mm mortars, 152mm artillery, 82mm mortars with priority over generic terms\n",
    "- **Vehicle and aircraft identification**: Su-30 jets, Mi-8 helicopters, T-72 tanks, BMP-2 vehicles, Pantsir-S1 systems\n",
    "- **Hierarchical specificity**: From generic \"drones\" to specific \"Ka-52 helicopters\" and \"bomber drones\"\n",
    "\n",
    "#### Infrastructure Impact Assessment\n",
    "\n",
    "- **Eight critical categories**: Power grid, medical services, transportation, communications, water supply, education, energy facilities, military infrastructure\n",
    "- **Damage pattern recognition**: 30+ specific patterns from \"power stations damaged\" to \"UAV equipment destroyed\"\n",
    "- **Modern warfare targets**: Electronic warfare stations, satellite terminals, industrial facilities, chemical plants\n",
    "\n",
    "#### Advanced Disorder Type Classification\n",
    "\n",
    "- **Interstate conflict priority**: Automatic classification for cross-border military operations between Russian and Ukrainian forces\n",
    "- **Ethnic conflict detection**: Specialised patterns for \"ethnic tensions escalated\" and minority community conflicts\n",
    "- **Protest versus civil unrest distinction**: Differentiates peaceful demonstrations from violent riots\n",
    "- **Separatist conflict identification**: NAF forces, breakaway regions, pro-Russian separatists\n",
    "\n",
    "### Quality Assurance Features\n",
    "\n",
    "#### Robust Error Handling\n",
    "\n",
    "- **Graceful degradation**: Processes malformed text without system failure\n",
    "- **Field completeness guarantee**: All fourteen fields present with \"unknown\" fallback where appropriate\n",
    "- **Exception management**: Comprehensive try-catch blocks with detailed error logging\n",
    "\n",
    "#### Cross-Border Intelligence Implementation\n",
    "\n",
    "- **Belgorod attribution**: Special handling ensures all Belgorod region mentions correctly attributed to Russia\n",
    "- **Interstate classification**: Automatic disorder_type assignment for cross-border military operations\n",
    "- **Actor-geography consistency**: Validates actor actions against geographic context\n",
    "\n",
    "This extraction system transforms raw conflict reports into structured, machine-learning-ready data whilst preserving the nuanced details essential for understanding modern Eastern European security dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fields(text):\n",
    "    \"\"\"\n",
    "    Extraction system with broad field coverage and robust error handling.\n",
    "    Covers 14 structured fields aimed at deciphering contemporary conflict scenarios.\n",
    "    \"\"\"\n",
    "    required_fields = [\n",
    "        'event_date', 'country', 'location', 'event_type',\n",
    "        'actor_1', 'actor_2', 'fatalities', 'civilian_casualties',\n",
    "        'property_damage', 'weapons_mentioned', 'casualty_type', 'attack_method',\n",
    "        'disorder_type', 'infrastructure_disruption'\n",
    "    ]\n",
    "    \n",
    "    extraction = {}\n",
    "\n",
    "    try:\n",
    "        text_str = str(text).strip()\n",
    "        if not text_str:\n",
    "            raise ValueError(\"Empty text input\")\n",
    "            \n",
    "        text_lower = text_str.lower()\n",
    "        \n",
    "        # 1. Event date extraction for a vast amount of formats\n",
    "        date_patterns = [\n",
    "            r'\\b(\\d{1,2})\\s+(January|February|March|April|May|June|July|August|September|October|November|December)\\s+(\\d{4})\\b',\n",
    "            r'\\b(\\d{1,2})\\s+(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\.?\\s+(\\d{4})\\b',\n",
    "            r'\\b(\\d{1,2})[-/](\\d{1,2})[-/](\\d{4})\\b',\n",
    "            r'\\b(\\d{4})[-/](\\d{1,2})[-/](\\d{1,2})\\b',\n",
    "            r'\\b(\\d{1,2})\\.(\\d{1,2})\\.(\\d{4})\\b',\n",
    "            r'\\bon\\s+(\\d{1,2}\\s+(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{4})\\b',\n",
    "            r'\\b(\\d{1,2})\\s+(?:of\\s+)?(January|February|March|April|May|June|July|August|September|October|November|December)\\s+(\\d{4})\\b',\n",
    "            r'\\bduring\\s+(\\d{1,2}\\s+(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{4})\\b'\n",
    "        ]\n",
    "        \n",
    "        for i, pattern in enumerate(date_patterns):\n",
    "            dates = re.findall(pattern, text_str, re.IGNORECASE)\n",
    "            if dates:\n",
    "                date_parts = dates[0]\n",
    "                if len(date_parts) == 3:\n",
    "                    if i <= 1:  # Month name formats\n",
    "                        extraction['event_date'] = f\"{date_parts[0]} {date_parts[1]} {date_parts[2]}\"\n",
    "                    else:  # Numeric formats\n",
    "                        extraction['event_date'] = f\"{date_parts[0]}-{date_parts[1]}-{date_parts[2]}\"\n",
    "                elif len(date_parts) == 1:  # Context pattern\n",
    "                    extraction['event_date'] = date_parts[0].strip()\n",
    "                break\n",
    "\n",
    "        # 2. Country Detection with Cross-Border Intelligence\n",
    "        def detect_country_with_context(text_lower):\n",
    "            # HIGHEST PRIORITY: Belgorod and Russian border regions to ensure attribution to Russia\n",
    "            belgorod_patterns = [\n",
    "                r'\\bin\\s+(?:the\\s+)?belgorod\\s+region',\n",
    "                r'\\bnear\\s+belgorod', r'\\bat\\s+belgorod', r'\\baround\\s+belgorod',\n",
    "                r'\\bin\\s+belgorod', r'\\bbelgorod\\s+(?:region|oblast|area)',\n",
    "                r'\\bkursk\\s+(?:region|oblast)', r'\\bbryansk\\s+(?:region|oblast)',\n",
    "                r'\\bvoronezh\\s+(?:region|oblast)', r'\\brostov\\s+(?:region|oblast)'\n",
    "            ]\n",
    "            \n",
    "            for pattern in belgorod_patterns:\n",
    "                if re.search(pattern, text_lower):\n",
    "                    extraction['country'] = 'russia'\n",
    "                    return 'russia'\n",
    "            \n",
    "            # SECOND PRIORITY: Cross-border operation patterns\n",
    "            cross_border_patterns = [\n",
    "                (r'\\bin\\s+(?:the\\s+)?(?:donetsk|luhansk|kharkiv|kyiv|lviv)\\s+(?:region|oblast)', 'ukraine'),\n",
    "                (r'\\brussian\\s+(?:military|forces?)\\s+(?:carried\\s+out|conducted|launched|attacked).*?(?:in|near|around)\\s+ukraine', 'ukraine'),\n",
    "                (r'\\bukrainian\\s+(?:military|forces?)\\s+(?:carried\\s+out|conducted|launched|attacked).*?(?:in|near|around).*?russia', 'russia'),\n",
    "            ]\n",
    "            \n",
    "            for pattern, country in cross_border_patterns:\n",
    "                if re.search(pattern, text_lower):\n",
    "                    extraction['country'] = country\n",
    "                    return country\n",
    "            \n",
    "            # THIRD PRIORITY: Standard country patterns\n",
    "            country_patterns = {\n",
    "                'ukraine': [\n",
    "                    r'\\bukraine\\b', r'\\bukrainian\\b', r'\\bkyiv\\b', r'\\bkharkiv\\b', r'\\blviv\\b', \n",
    "                    r'\\bdnipro\\b', r'\\bodesa\\b', r'\\bdonetsk\\b', r'\\bluhansk\\b', r'\\bmariupol\\b', \n",
    "                    r'\\bkostiantynivka\\b', r'\\bzaporizhzhia\\b', r'\\bkremenchuk\\b', r'\\bpoltava\\b',\n",
    "                    r'\\bchernihiv\\b', r'\\bsumy\\b', r'\\bkherson\\b', r'\\bmykolaiv\\b', r'\\bpavlopil\\b',\n",
    "                    r'\\bprokhody\\b', r'\\bandriivka\\b', r'\\bpokrovsk\\b', r'\\bzaporizhia\\b', r'\\bcrimea\\b'\n",
    "                ],\n",
    "                'russia': [\n",
    "                    r'\\brussia\\b', r'\\brussian\\b', r'\\bmoscow\\b', r'\\bkhabarovsk\\b', r'\\bkremlin\\b', \n",
    "                    r'\\bst\\.?\\s*petersburg\\b', r'\\bbelgorod\\b', r'\\bkursk\\b',\n",
    "                    r'\\bbryansk\\b', r'\\bvoronezh\\b', r'\\bsmolensk\\b',\n",
    "                    r'\\btula\\b', r'\\bkaluga\\b'\n",
    "                ],\n",
    "                'poland': [r'\\bpoland\\b', r'\\bpolish\\b', r'\\bwarsaw\\b', r'\\bkrakow\\b', r'\\bgdansk\\b', r'\\bwroclaw\\b'],\n",
    "                'romania': [\n",
    "                    r'\\bromania\\b', r'\\bromanian\\b', r'\\bbucharest\\b', r'\\bcluj\\b', r'\\btimisoara\\b',\n",
    "                    r'\\biasi\\b', r'\\bsibiu\\b', r'\\bbuzau\\b', r'\\bfocsani\\b'\n",
    "                ],\n",
    "                'belarus': [r'\\bbelarus\\b', r'\\bbelarusian\\b', r'\\bminsk\\b', r'\\bgomel\\b', r'\\bbrest\\b'],\n",
    "                'bulgaria': [r'\\bbulgaria\\b', r'\\bbulgarian\\b', r'\\bsofia\\b', r'\\bplovdiv\\b', r'\\bvarna\\b'],\n",
    "                'moldova': [r'\\bmoldova\\b', r'\\bmoldovan\\b', r'\\bchisinau\\b', r'\\btiraspol\\b', r'\\btransnistria\\b'],\n",
    "                'czech republic': [r'\\bczech\\b', r'\\bprague\\b', r'\\bbrno\\b', r'\\bostrava\\b'],\n",
    "                'hungary': [r'\\bhungary\\b', r'\\bhungarian\\b', r'\\bbudapest\\b', r'\\bdebrecen\\b'],\n",
    "                'slovakia': [r'\\bslovakia\\b', r'\\bslovak\\b', r'\\bbratislava\\b', r'\\bkosice\\b'],\n",
    "                'lithuania': [r'\\blithuania\\b', r'\\blithuanian\\b', r'\\bvilnius\\b', r'\\bkaunas\\b'],\n",
    "                'latvia': [r'\\blatvia\\b', r'\\blatvian\\b', r'\\briga\\b', r'\\bdaugavpils\\b'],\n",
    "                'estonia': [r'\\bestonia\\b', r'\\bestonian\\b', r'\\btallinn\\b', r'\\btartu\\b'],\n",
    "            }\n",
    "            \n",
    "            for country, patterns in country_patterns.items():\n",
    "                if any(re.search(pattern, text_lower) for pattern in patterns):\n",
    "                    extraction['country'] = country\n",
    "                    return country\n",
    "            \n",
    "            return None\n",
    "        \n",
    "        detect_country_with_context(text_lower)\n",
    "\n",
    "        # 3. Location extraction\n",
    "        location_patterns = [\n",
    "            r'(?:in|at|near|across|including|from|to|within|on)\\s+(?:the\\s+)?([A-Z][a-z]{2,}(?:skiy|sky|sk|ske|ski)?\\s+(?:district|region|oblast|area|zone))',\n",
    "            r'(?:village|city|town|settlement|locality)\\s+(?:of\\s+)?([A-Z][a-z]{2,})',\n",
    "            r'(?:in|at|near|around|from|to|shelled|struck|attacked|targeted|on)\\s+([A-Z][a-z]{2,}(?:\\s+[A-Z][a-z]+)?)',\n",
    "            r'\\(([A-Z][a-z]{2,}(?:\\s*,\\s*[A-Z][a-z]+)*)\\)',\n",
    "            r'\\b([A-Z][a-z]{2,})(?:\\s*,?\\s*(?:region|oblast|city|town|district|province|area|zone))\\b',\n",
    "            r'\\b([A-Z][a-z]{2,})(?:\\s+(?:airport|station|bridge|port|base|hospital|school|market|facility))\\b'\n",
    "        ]\n",
    "        \n",
    "        locations = set()\n",
    "        exclude_words = {\n",
    "            'According', 'Russian', 'Ukrainian', 'Government', 'Forces', 'Military', \n",
    "            'Police', 'National', 'State', 'Public', 'Local', 'Regional', 'Federal',\n",
    "            'Armed', 'Security', 'Border', 'Emergency', 'Special', 'International',\n",
    "            'European', 'Eastern', 'Western', 'Northern', 'Southern', 'Central',\n",
    "            'President', 'Minister', 'Official', 'Spokesman', 'Commander', 'General',\n",
    "            'Today', 'Yesterday', 'Morning', 'Evening', 'Night', 'Afternoon',\n",
    "            'January', 'February', 'March', 'April', 'May', 'June', 'July',\n",
    "            'August', 'September', 'October', 'November', 'December',\n",
    "            'Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday',\n",
    "            'Hospital', 'School', 'Airport', 'Station', 'Bridge', 'Market', 'Building',\n",
    "            'Three', 'Several', 'Multiple', 'Various', 'Many', 'Two', 'Four', 'Five'\n",
    "        }\n",
    "        \n",
    "        for pattern in location_patterns:\n",
    "            matches = re.findall(pattern, text_str)\n",
    "            for match in matches:\n",
    "                if ',' in match:\n",
    "                    for sub_location in match.split(','):\n",
    "                        clean_loc = sub_location.strip()\n",
    "                        if (len(clean_loc) >= 2 and \n",
    "                            clean_loc not in exclude_words and \n",
    "                            not any(word in clean_loc for word in ['The', 'And', 'But', 'For', 'With']) and\n",
    "                            re.match(r'^[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*$', clean_loc)):\n",
    "                            locations.add(clean_loc)\n",
    "                else:\n",
    "                    if (len(match) >= 2 and \n",
    "                        match not in exclude_words and \n",
    "                        not any(word in match for word in ['The', 'And', 'But', 'For', 'With']) and\n",
    "                        re.match(r'^[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*$', match)):\n",
    "                        locations.add(match)\n",
    "        \n",
    "        if locations:\n",
    "            extraction['location'] = list(locations)[:8]\n",
    "\n",
    "        # 4. Event type classification\n",
    "        event_patterns = [\n",
    "            ('battles', [\n",
    "                r'\\bclash(?:es)?\\b', r'\\bfighting\\b', r'\\bcombat\\b', r'\\bbattle(?:s)?\\b', \n",
    "                r'\\bengagement(?:s)?\\b', r'\\bskirmish(?:es)?\\b', r'\\bconfrontation\\b',\n",
    "                r'\\bassault\\s+actions?\\b',\n",
    "                r'\\barmed\\s+(?:clashes?|confrontations?)\\b',\n",
    "                r'\\bmilitary\\s+(?:clashes?|engagement|confrontation)\\b',\n",
    "                r'\\bforces?\\s+(?:clashed|engaged|fought)\\b',\n",
    "                r'\\b(?:ukrainian|russian)\\s+forces?\\s+(?:clashed|engaged|fought)\\s+(?:with|against)',\n",
    "                r'\\bground\\s+(?:combat|fighting|clashes?)\\b',\n",
    "                r'\\bmilitary\\s+units?\\s+(?:clashed|engaged)',\n",
    "                r'\\bgovernment\\s+forces?\\s+(?:clashed|fought)\\s+(?:with|against)',\n",
    "                r'\\b(?:territorial|armed)\\s+forces?\\s+(?:clashed|engaged)'\n",
    "            ]),\n",
    "            ('remote_violence', [\n",
    "                r'\\bair\\s*strike(?:s)?\\b', r'\\bairstrike(?:s)?\\b', r'\\bshelled\\b', r'\\bshelling\\b', \n",
    "                r'\\bmissile(?:s)?\\s+(?:attack|strike|launched|fired)\\b',\n",
    "                r'\\brussian\\s+forces?\\s+launched\\s+missiles?\\b',\n",
    "                r'\\bdrone.*?(?:attack|strike)(?:s)?\\b', \n",
    "                r'\\bartillery.*?(?:fire|attack|shelling)\\b', r'\\bmortar.*?(?:fire|attack)\\b', \n",
    "                r'\\baerial\\s+bomb(?:s)?\\b', r'\\bfab[-\\s]?\\d+\\b', r'\\bguided\\s+bombs?\\b',\n",
    "                r'\\rocket\\s+(?:attack|strike)(?:s)?\\b', r'\\bbombardment\\b',\n",
    "                r'\\bshadow\\s+missile\\s+strikes?\\b'\n",
    "            ]),\n",
    "            ('protests', [\n",
    "                r'\\bpeaceful\\s+protest\\b', r'\\bdemonstration(?:s)?\\b', r'\\brall(?:y|ies)\\b', \n",
    "                r'\\bmarch(?:es)?\\b',\n",
    "                r'\\b(?:went\\s+on|called|announced)\\s+a\\s+strike\\b',\n",
    "                r'\\b(?:workers?|unions?|teachers?|miners?|doctors?|nurses?)\\s+strike(?:s|d)?\\b',        \n",
    "                r'\\bunrest\\b', r'\\bdisorder\\b', r'\\bactivist(?:s)?\\b',\n",
    "                r'\\bspontaneous\\s+protest\\b', \n",
    "                r'\\bshort\\s+demonstration\\b',\n",
    "            ]),\n",
    "            ('explosions', [\n",
    "                r'\\bbomb(?:ing)?(?:s)?\\b', r'\\bexplosion(?:s)?\\b', r'\\bblast(?:s)?\\b', \n",
    "                r'\\bdetonation(?:s)?\\b', r'\\bmine(?:s)?\\b', r'\\bied\\b'\n",
    "            ]),\n",
    "            ('violence_against_civilians', [\n",
    "                r'\\bassassination\\b', r'\\bexecution\\b', r'\\bkidnapping\\b', r'\\babduction\\b', \n",
    "                r'\\btorture\\b', r'\\bmassacre\\b'\n",
    "            ])\n",
    "        ]\n",
    "\n",
    "        # Classification with military context priority\n",
    "        for event_type, patterns in event_patterns:\n",
    "            if any(re.search(pattern, text_lower) for pattern in patterns):\n",
    "                extraction['event_type'] = event_type\n",
    "                break \n",
    "\n",
    "        # Context-aware refinement based on actors\n",
    "        if extraction.get('event_type', 'unknown') == 'unknown':\n",
    "            a1 = extraction.get('actor_1', '').lower()\n",
    "            a2 = extraction.get('actor_2', '').lower()\n",
    "            \n",
    "            # Military vs Military = battles (even without explicit battle words)\n",
    "            military_indicators = ['military', 'forces', 'troops', 'soldiers', 'armed', 'army', 'naf', 'rebel']\n",
    "            a1_military = any(term in a1 for term in military_indicators)\n",
    "            a2_military = any(term in a2 for term in military_indicators)\n",
    "            \n",
    "            if a1_military and a2_military:\n",
    "                # Check for weapons context to confirm it's combat\n",
    "                weapon_context = any(word in text_lower for word in ['fired', 'mortars', 'artillery', 'weapons', 'shells'])\n",
    "                if weapon_context:\n",
    "                    extraction['event_type'] = 'battles'\n",
    "                else:\n",
    "                    extraction['event_type'] = 'remote_violence'\n",
    "            elif any(term in text_lower for term in ['fired', 'shelled', 'artillery', 'missiles', 'bombing']):\n",
    "                extraction['event_type'] = 'remote_violence'\n",
    "\n",
    "        # Further refinement for mortar/artillery context\n",
    "        weapons_mentioned = extraction.get('weapons_mentioned', [])\n",
    "        if isinstance(weapons_mentioned, list):\n",
    "            weapons_lower = [w.lower() for w in weapons_mentioned]\n",
    "        else:\n",
    "            weapons_lower = []\n",
    "\n",
    "        mortar_context = (\n",
    "            re.search(r'\\bfired\\s+with\\s+\\d+\\s*mm\\s+mortars?\\b', text_lower) or\n",
    "            re.search(r'\\bmortars?\\b', text_lower) or\n",
    "            any('mortar' in w for w in weapons_lower)\n",
    "        )\n",
    "\n",
    "        if mortar_context and extraction.get('event_type') == 'unknown':\n",
    "            a1 = extraction.get('actor_1', '').lower()\n",
    "            a2 = extraction.get('actor_2', '').lower()\n",
    "            military_like = lambda s: any(x in s for x in ['military', 'forces', 'troops', 'soldiers', 'guard'])\n",
    "            \n",
    "            if military_like(a1) and military_like(a2):\n",
    "                extraction['event_type'] = 'battles'\n",
    "            else:\n",
    "                extraction['event_type'] = 'remote_violence'\n",
    "\n",
    "        # 5. Actor Detection\n",
    "        protest_lead = re.search(r'\\bprotesters?\\s+(?:gathered|marched|demonstrated|rallied)\\b', text_lower)\n",
    "        police_action = re.search(r'\\bpolice\\s+(?:forces?|officers?)\\s+(?:dispersed|arrested|detained|confronted|clashed)\\b', text_lower)\n",
    "        if protest_lead:\n",
    "            extraction['actor_1'] = 'protesters'\n",
    "            extraction['actor_2'] = 'police forces' if police_action else \"unknown\"\n",
    "\n",
    "        primary_actor_patterns = [\n",
    "            # TIER 1: Action + Nationality + Force (Highest Priority)\n",
    "            (r'\\bukrainian\\s+(?:military|armed\\s+)?forces?\\s+(?:carried\\s+out|conducted|launched|attacked|fired|struck|shelled|responded)', 'Ukrainian military forces'),\n",
    "            (r'\\brussian\\s+(?:military|armed\\s+)?forces?\\s+(?:carried\\s+out|conducted|launched|attacked|fired|struck|shelled)', 'Russian military forces'),\n",
    "            (r'\\bnaf\\s+(?:rebel\\s+)?forces?\\s+(?:fired|attacked|launched|conducted|struck)', 'NAF rebel forces'),\n",
    "            (r'\\bpolice\\s+(?:forces?|officers?)\\s+(?:responded|intervened|conducted|arrested|dispersed)', 'police forces'),\n",
    "            \n",
    "            # TIER 1.5: SPECIFIC UNIT TYPES\n",
    "            (r'\\bterritorial\\s+defence\\s+(?:\\(coded\\s+to\\s+\\w+\\)|forces?)', 'territorial defence forces'),\n",
    "            (r'\\bmarines?\\s+(?:\\(coded\\s+to\\s+\\w+\\)|forces?)', 'marine forces'),\n",
    "            (r'\\bnational\\s+guard\\s+(?:\\(coded\\s+to\\s+\\w+\\)|forces?)', 'national guard forces'),\n",
    "            (r'\\brussian\\s+air\\s+forces?\\b', 'Russian air forces'),\n",
    "            (r'\\bukrainian\\s+partisans?\\b', 'Ukrainian partisans'),\n",
    "            (r'\\bdonbas\\s+people\\'?s\\s+militia\\b', 'Donbas People\\'s Militia'),\n",
    "            (r'\\brussian\\s+forces?\\b', 'Russian Forces'),\n",
    "            \n",
    "            # TIER 2: CIVILIAN GROUPS\n",
    "            (r'\\bsupporters?\\b', 'supporters'),\n",
    "            (r'\\bemployees?\\b', 'employees'),\n",
    "            (r'\\bstudents?\\b', 'students'),\n",
    "            (r'\\bpolicemen\\b', 'police forces'),\n",
    "            (r'\\bcitizens?\\b', 'citizens'),\n",
    "            (r'\\bfarmers?\\b', 'farmers'),\n",
    "            \n",
    "            # TIER 3: PROTEST GROUPS AND CIVIL SOCIETY\n",
    "            (r'\\bprotesters?\\s+(?:gathered|marched|demonstrated|clashed|confronted)', 'protesters'),\n",
    "            (r'\\bdemonstrators?\\s+(?:gathered|marched|rallied|clashed)', 'demonstrators'),\n",
    "            (r'\\bactivists?\\s+(?:organized|led|participated|protested)', 'activists'),\n",
    "            (r'\\bopposition\\s+(?:groups?|supporters?|activists?)\\s+(?:organized|demonstrated)', 'opposition groups'),\n",
    "            (r'\\btrade\\s+unions?\\s+(?:organized|called|led)', 'trade unions'),\n",
    "            (r'\\bstudent(?:s)?\\s+(?:protesters?|activists?|groups?)', 'student protesters'),\n",
    "            (r'\\bcivil\\s+society\\s+(?:groups?|organizations?)', 'civil society groups'),\n",
    "            (r'\\bpro[-\\s]?democracy\\s+(?:activists?|protesters?)', 'pro-democracy activists'),\n",
    "            (r'\\banti[-\\s]?government\\s+(?:protesters?|groups?)', 'anti-government protesters'),\n",
    "\n",
    "            # TIER 2: CIVILIAN GROUPS\n",
    "            (r'\\bsupporters?\\b', 'supporters'),\n",
    "            (r'\\bemployees?\\b', 'employees'),\n",
    "            (r'\\bstudents?\\b', 'students'),\n",
    "            (r'\\bpolicemen\\b', 'police forces'),\n",
    "            (r'\\bcitizens?\\b', 'citizens'),\n",
    "            (r'\\bfarmers?\\b', 'farmers'),\n",
    "            \n",
    "            # TIER 4: REGIONAL MILITARY FORCES\n",
    "            (r'\\bpolish\\s+(?:military|forces?|army)\\b', 'Polish military forces'),\n",
    "            (r'\\bestonian\\s+(?:military|forces?|defence\\s+forces?)\\b', 'Estonian military forces'),\n",
    "            (r'\\blatvian\\s+(?:military|forces?|army)\\b', 'Latvian military forces'),\n",
    "            (r'\\blithuanian\\s+(?:military|forces?|army)\\b', 'Lithuanian military forces'),\n",
    "            (r'\\bbelarusian\\s+(?:military|forces?|security\\s+forces?)\\b', 'Belarusian military forces'),\n",
    "            (r'\\bromanian\\s+(?:military|forces?|army)\\b', 'Romanian military forces'),\n",
    "            (r'\\bbulgarian\\s+(?:military|forces?|army)\\b', 'Bulgarian military forces'),\n",
    "            (r'\\bczech\\s+(?:military|forces?|army)\\b', 'Czech military forces'),\n",
    "            (r'\\bhungarian\\s+(?:military|forces?|army)\\b', 'Hungarian military forces'),\n",
    "            (r'\\bslovak\\s+(?:military|forces?|army)\\b', 'Slovak military forces'),\n",
    "            (r'\\bmoldovan\\s+(?:military|forces?|army)\\b', 'Moldovan military forces'),\n",
    "            \n",
    "            # TIER 5: SECURITY AND SPECIALISED FORCES\n",
    "            (r'\\briot\\s+police\\b', 'riot police'),\n",
    "            (r'\\bspecial\\s+police\\s+(?:forces?|units?)\\b', 'special police forces'),\n",
    "            (r'\\bborder\\s+(?:guards?|forces?|patrol)\\b', 'border guards'),\n",
    "            (r'\\bomon\\s+(?:forces?|troops|units?)\\b', 'OMON forces'),\n",
    "            (r'\\binterior\\s+ministry\\s+(?:forces?|troops)\\b', 'interior ministry forces'),\n",
    "            (r'\\bsecurity\\s+services\\b', 'security services'),\n",
    "            \n",
    "            # TIER 6: PARAMILITARY AND IRREGULAR FORCES\n",
    "            (r'\\bwagner\\s+(?:group|forces?|mercenaries?)\\b', 'Wagner forces'),\n",
    "            (r'\\bvolunteer\\s+(?:battalions?|units?|forces?)\\b', 'volunteer forces'),\n",
    "            (r'\\bterritorial\\s+defence\\s+(?:forces?|units?)\\b', 'territorial defence forces'),\n",
    "            (r'\\bprivate\\s+military\\s+(?:companies?|contractors?)\\b', 'private military forces'),\n",
    "            \n",
    "            # TIER 7: SEPARATIST AND REGIONAL GROUPS\n",
    "            (r'\\btransnistrian\\s+(?:forces?|separatists?)\\b', 'Transnistrian separatist forces'),\n",
    "            (r'\\bpro[-\\s]?russian\\s+(?:separatists?|forces?|militants?)\\b', 'pro-Russian separatist forces'),\n",
    "            (r'\\bbreakaway\\s+(?:forces?|groups?|regions?)\\b', 'breakaway forces'),\n",
    "            \n",
    "            # TIER 8: Subject + Action (Medium Priority)\n",
    "            (r'\\bukrainian\\s+(?:military|forces?|army|troops|soldiers?)\\s+(?:launched|fired|attacked|conducted)', 'Ukrainian military forces'),\n",
    "            (r'\\brussian\\s+(?:military|forces?|army|troops|soldiers?)\\s+(?:launched|fired|attacked|conducted)', 'Russian military forces'),\n",
    "            \n",
    "            # TIER 9: Nationality + Force Type (Lower Priority)\n",
    "            (r'\\bukrainian\\s+(?:military|forces?|army|troops|government\\s+soldiers?)\\b', 'Ukrainian military forces'),\n",
    "            (r'\\brussian\\s+(?:military|forces?|army|troops|government\\s+soldiers?)\\b', 'Russian military forces'),\n",
    "            (r'\\bnaf\\s+(?:rebel\\s+)?forces?\\b', 'NAF rebel forces'),\n",
    "            (r'\\bpolice\\s+(?:forces?|officers?)\\b', 'police forces'),\n",
    "            \n",
    "            # TIER 10: Generic Fallback (Lowest Priority)\n",
    "            (r'\\bmilitary\\s+forces?\\b', 'military forces'),\n",
    "            (r'\\bgovernment\\s+forces?\\b', 'government forces'),\n",
    "            (r'\\bsecurity\\s+forces?\\b', 'security forces'),\n",
    "        ]\n",
    "        \n",
    "        if 'actor_1' not in extraction:\n",
    "            actor_1 = \"unknown\"\n",
    "            for pattern, actor_name in primary_actor_patterns:\n",
    "                if re.search(pattern, text_lower):\n",
    "                    actor_1 = actor_name\n",
    "                    break\n",
    "            extraction['actor_1'] = actor_1\n",
    "        \n",
    "        # 6. Secondary Actor Detection\n",
    "        secondary_actor_patterns = [\n",
    "            # TIER 0: Direct targeting with specific context (HIGHEST PRIORITY)\n",
    "            (r'fired\\s+(?:with\\s+[^.]*?)?\\s*(?:at|towards?|against)\\s+(?:the\\s+)?military\\s+forces?\\s+of\\s+ukraine', 'Ukrainian military forces'),\n",
    "            (r'fired\\s+(?:with\\s+[^.]*?)?\\s*(?:at|towards?|against)\\s+(?:the\\s+)?military\\s+forces?\\s+of\\s+russia', 'Russian military forces'),\n",
    "    \n",
    "            # TIER 1: Direct Targeting with Weapons\n",
    "            (r'fired\\s+(?:with\\s+[^.]*?)?\\s*(?:at|towards?|against)\\s+(?:the\\s+)?(ukrainian\\s+(?:military|government|forces?|soldiers?|personnel))', 'Ukrainian military forces'),\n",
    "            (r'fired\\s+(?:with\\s+[^.]*?)?\\s*(?:at|towards?|against)\\s+(?:the\\s+)?(russian\\s+(?:military|government|forces?|soldiers?|personnel))', 'Russian military forces'),\n",
    "            (r'(?:attacked|struck|targeted|shelled|bombed)\\s+(ukrainian\\s+(?:military|forces?|positions?|positioned?|soldiers?))', 'Ukrainian military forces'),\n",
    "            (r'(?:attacked|struck|targeted|shelled|bombed)\\s+(russian\\s+(?:military|forces?|positions?|positioned?|soldiers?))', 'Russian military forces'),\n",
    "\n",
    "            # TIER 1.5: SPECIFIC UNIT TYPES AS TARGETS\n",
    "            (r'(?:attacked|struck|targeted|fired\\s+at)\\s+(territorial\\s+defence\\s+(?:forces?|units?))', 'territorial defence forces'),\n",
    "            (r'(?:attacked|struck|targeted|fired\\s+at)\\s+(marines?\\s+(?:forces?|units?))', 'marine forces'),\n",
    "            (r'(?:attacked|struck|targeted|fired\\s+at)\\s+(national\\s+guard\\s+(?:forces?|units?))', 'national guard forces'),\n",
    "            (r'(?:attacked|struck|targeted|fired\\s+at)\\s+(russian\\s+air\\s+forces?)', 'Russian air forces'),\n",
    "            (r'(?:attacked|struck|targeted|fired\\s+at)\\s+(ukrainian\\s+partisans?)', 'Ukrainian partisans'),\n",
    "            (r'(?:attacked|struck|targeted|fired\\s+at)\\s+(donbas\\s+people\\'?s\\s+militia)', 'Donbas People\\'s Militia'),\n",
    "\n",
    "            # TIER 2: Cross-Border Targeting Operations\n",
    "            (r'(?:strikes?|attacks?)\\s+against\\s+(?:the\\s+)?(russian\\s+(?:military|forces?))', 'Russian military forces'),\n",
    "            (r'(?:strikes?|attacks?)\\s+against\\s+(?:the\\s+)?(ukrainian\\s+(?:military|forces?))', 'Ukrainian military forces'),\n",
    "            \n",
    "            # TIER 2.5: Casualty-Based Detection (High Value)\n",
    "            (r'(ukrainian\\s+government\\s+soldiers?)\\s+were\\s+(?:injured|wounded|killed|hurt)', 'Ukrainian military forces'),\n",
    "            (r'(three\\s+ukrainian\\s+government\\s+soldiers?)', 'Ukrainian military forces'),\n",
    "            (r'(?:killed|injured|wounded)\\s+(ukrainian\\s+(?:military|soldiers?|forces?|personnel))', 'Ukrainian military forces'),\n",
    "            (r'(?:killed|injured|wounded)\\s+(russian\\s+(?:military|soldiers?|forces?|personnel))', 'Russian military forces'),\n",
    "            \n",
    "            # TIER 3: PROTEST CONTEXT\n",
    "            (r'police\\s+(?:dispersed|arrested|detained|confronted|clashed\\s+with)\\s+(protesters?)', lambda m: 'protesters'),\n",
    "            (r'police\\s+(?:dispersed|arrested|detained|confronted|clashed\\s+with)\\s+(demonstrators?)', lambda m: 'demonstrators'),\n",
    "            (r'police\\s+(?:dispersed|arrested|detained|confronted|clashed\\s+with)\\s+(activists?)', lambda m: 'activists'),\n",
    "            (r'authorities\\s+(?:arrested|detained|confronted)\\s+(opposition\\s+(?:groups?|activists?|supporters?))', lambda m: m.group(1)),\n",
    "            (r'(?:clashed\\s+with|confronted)\\s+(civil\\s+society\\s+(?:groups?|organizations?))', lambda m: m.group(1)),\n",
    "            (r'(?:targeted|arrested|detained)\\s+(trade\\s+unions?)', lambda m: m.group(1)),\n",
    "            (r'(?:confronted|clashed\\s+with)\\s+(student\\s+(?:protesters?|activists?))', lambda m: m.group(1)),\n",
    "            (r'(?:dispersed|confronted)\\s+(anti[-\\s]?government\\s+protesters?)', lambda m: m.group(1)),\n",
    "            (r'(?:targeted|attacked)\\s+(pro[-\\s]?democracy\\s+activists?)', lambda m: m.group(1)),\n",
    "            \n",
    "            # TIER 4: CIVILIAN GROUPS AS TARGETS\n",
    "            (r'(?:targeted|attacked|arrested)\\s+(supporters?)', lambda m: 'supporters'),\n",
    "            (r'(?:targeted|attacked|arrested)\\s+(employees?)', lambda m: 'employees'),\n",
    "            (r'(?:targeted|attacked|arrested)\\s+(students?)', lambda m: 'students'),\n",
    "            (r'(?:targeted|attacked|arrested)\\s+(citizens?)', lambda m: 'citizens'),\n",
    "            (r'(?:targeted|attacked|arrested)\\s+(farmers?)', lambda m: 'farmers'),\n",
    "            \n",
    "            # TIER 5: SECURITY FORCES TARGETING CIVILIANS\n",
    "            (r'(?:riot\\s+police|omon\\s+forces?)\\s+(?:dispersed|confronted)\\s+(protesters?)', lambda m: 'protesters'),\n",
    "            (r'security\\s+forces?\\s+(?:arrested|detained)\\s+(opposition\\s+activists?)', lambda m: m.group(1)),\n",
    "            (r'government\\s+forces?\\s+(?:crackdown\\s+on|targeted)\\s+(protesters?)', lambda m: 'protesters'),\n",
    "            \n",
    "            # TIER 6: COUNTER-PROTEST DYNAMICS\n",
    "            (r'(?:clashed\\s+with|confronted)\\s+(pro[-\\s]?government\\s+supporters?)', lambda m: m.group(1)),\n",
    "            (r'(?:attacked|targeted)\\s+(counter[-\\s]?protesters?)', lambda m: m.group(1)),\n",
    "            \n",
    "            # TIER 7: MILITARY TARGETING (ALL REGIONAL FORCES)\n",
    "            (r'(?:attacked|struck|targeted|fired\\s+at)\\s+(polish\\s+(?:military|forces?))', 'Polish military forces'),\n",
    "            (r'(?:attacked|struck|targeted|fired\\s+at)\\s+(estonian\\s+(?:military|forces?))', 'Estonian military forces'),\n",
    "            (r'(?:attacked|struck|targeted|fired\\s+at)\\s+(latvian\\s+(?:military|forces?))', 'Latvian military forces'),\n",
    "            (r'(?:attacked|struck|targeted|fired\\s+at)\\s+(lithuanian\\s+(?:military|forces?))', 'Lithuanian military forces'),\n",
    "            (r'(?:attacked|struck|targeted|fired\\s+at)\\s+(belarusian\\s+(?:military|forces?))', 'Belarusian military forces'),\n",
    "            (r'(?:attacked|struck|targeted|fired\\s+at)\\s+(romanian\\s+(?:military|forces?))', 'Romanian military forces'),\n",
    "            (r'(?:attacked|struck|targeted|fired\\s+at)\\s+(bulgarian\\s+(?:military|forces?))', 'Bulgarian military forces'),\n",
    "            (r'(?:attacked|struck|targeted|fired\\s+at)\\s+(czech\\s+(?:military|forces?))', 'Czech military forces'),\n",
    "            (r'(?:attacked|struck|targeted|fired\\s+at)\\s+(hungarian\\s+(?:military|forces?))', 'Hungarian military forces'),\n",
    "            (r'(?:attacked|struck|targeted|fired\\s+at)\\s+(slovak\\s+(?:military|forces?))', 'Slovak military forces'),\n",
    "            (r'(?:attacked|struck|targeted|fired\\s+at)\\s+(moldovan\\s+(?:military|forces?))', 'Moldovan military forces'),\n",
    "            \n",
    "            # TIER 8: SECURITY APPARATUS AS TARGETS\n",
    "            (r'(?:attacked|targeted|confronted)\\s+(riot\\s+police)', 'riot police'),\n",
    "            (r'(?:attacked|targeted|fired\\s+at)\\s+(special\\s+police\\s+(?:forces?|units?))', 'special police forces'),\n",
    "            (r'(?:attacked|targeted|struck)\\s+(border\\s+(?:guards?|forces?))', 'border guards'),\n",
    "            (r'(?:attacked|targeted|confronted)\\s+(omon\\s+(?:forces?|troops))', 'OMON forces'),\n",
    "            (r'(?:attacked|targeted|struck)\\s+(interior\\s+ministry\\s+(?:forces?|troops))', 'interior ministry forces'),\n",
    "            (r'(?:targeted|attacked)\\s+(security\\s+services)', 'security services'),\n",
    "            \n",
    "            # TIER 9: PARAMILITARY AND IRREGULAR FORCES AS TARGETS\n",
    "            (r'(?:attacked|struck|targeted|fired\\s+at)\\s+(wagner\\s+(?:group|forces?))', 'Wagner forces'),\n",
    "            (r'(?:attacked|struck|targeted)\\s+(volunteer\\s+(?:battalions?|forces?))', 'volunteer forces'),\n",
    "            (r'(?:attacked|struck|targeted)\\s+(private\\s+military\\s+(?:companies?|contractors?))', 'private military forces'),\n",
    "            \n",
    "            # TIER 10: SEPARATIST GROUPS AS TARGETS\n",
    "            (r'(?:attacked|struck|targeted|fired\\s+at)\\s+(transnistrian\\s+(?:forces?|separatists?))', 'Transnistrian separatist forces'),\n",
    "            (r'(?:attacked|struck|targeted)\\s+(pro[-\\s]?russian\\s+(?:separatists?|forces?))', 'pro-Russian separatist forces'),\n",
    "            (r'(?:attacked|struck|targeted)\\s+(naf\\s+(?:rebel\\s+)?forces?)', 'NAF rebel forces'),\n",
    "            (r'(?:attacked|struck|targeted)\\s+(breakaway\\s+(?:forces?|groups?))', 'breakaway forces'),\n",
    "            \n",
    "            # TIER 11: Position and Equipment\n",
    "            (r'(?:positions?\\s+of|near|at|positioned)\\s+(ukrainian\\s+(?:military|forces?))', 'Ukrainian military forces'),\n",
    "            (r'(?:positions?\\s+of|near|at|positioned)\\s+(russian\\s+(?:military|forces?))', 'Russian military forces'),\n",
    "            (r'(?:russian\\s+(?:military|forces?)\\s+positioned)', 'Russian military forces'),\n",
    "            (r'(?:ukrainian\\s+(?:military|forces?)\\s+positioned)', 'Ukrainian military forces'),\n",
    "                   \n",
    "            # TIER 12: Opposition/Conflict Context\n",
    "            (r'(?:clashed\\s+with|confronted|fought\\s+(?:against|with))\\s+(ukrainian\\s+(?:military|forces?|troops))', 'Ukrainian military forces'),\n",
    "            (r'(?:clashed\\s+with|confronted|fought\\s+(?:against|with))\\s+(russian\\s+(?:military|forces?|troops))', 'Russian military forces'),\n",
    "            (r'(?:clashed\\s+with|confronted|fought\\s+(?:against|with))\\s+(protesters?|demonstrators?)', lambda m: m.group(1)),\n",
    "        ]\n",
    "        \n",
    "        actor_2 = extraction.get('actor_2', 'unknown')\n",
    "        for pattern, actor_func in secondary_actor_patterns:\n",
    "            match = re.search(pattern, text_lower)\n",
    "            if match:\n",
    "                potential_actor_2 = actor_func(match) if callable(actor_func) else actor_func\n",
    "                if (potential_actor_2 != extraction.get('actor_1', 'unknown') and \n",
    "                    potential_actor_2 != \"unknown\" and \n",
    "                    len(potential_actor_2) > 3):\n",
    "                    actor_2 = potential_actor_2\n",
    "                    break\n",
    "        \n",
    "        extraction['actor_2'] = actor_2\n",
    "\n",
    "        # 7. Casualty extraction\n",
    "        fatality_patterns = [\n",
    "            r'\\bkilling\\s+(\\d+)(?:\\s+(?:people|civilians|soldiers|persons))?\\b',\n",
    "            r'(\\d+)\\s+(?:people\\s+)?(?:were\\s+)?(?:killed|dead|died|deaths?|fatalities)',\n",
    "            r'(?:killed|deaths?|fatalities|casualties)\\s*:?\\s*(\\d+)',\n",
    "            r'(\\d+)\\s+(?:soldiers?|troops|civilians?|people|persons?)\\s+(?:were\\s+)?(?:killed|died|lost\\s+their\\s+lives)',\n",
    "            r'death\\s+toll\\s*:?\\s*(\\d+)',\n",
    "            r'(\\d+)\\s+confirmed\\s+(?:dead|deaths?|killed)',\n",
    "            r'at\\s+least\\s+(\\d+)\\s+(?:killed|dead|deaths?)',\n",
    "            r'(\\d+)\\s+(?:have\\s+)?died',\n",
    "            r'total\\s+(?:of\\s+)?(\\d+)\\s+(?:killed|dead|deaths?)'\n",
    "        ]\n",
    "        \n",
    "        for pattern in fatality_patterns:\n",
    "            matches = re.findall(pattern, text_lower)\n",
    "            if matches:\n",
    "                try:\n",
    "                    fatalities = int(matches[0])\n",
    "                    if 1 <= fatalities <= 5000:\n",
    "                        extraction['fatalities'] = fatalities\n",
    "                        break\n",
    "                except (ValueError, TypeError):\n",
    "                    continue\n",
    "\n",
    "        # Civilian casualties extraction\n",
    "        civilian_patterns = [\n",
    "            r'(\\d+)\\s+civilians?\\s+(?:were\\s+)?(?:killed|injured|wounded|casualties|hurt|harmed)',\n",
    "            r'civilian\\s+(?:casualties|deaths?|injured|wounded|killed)\\s*:?\\s*(\\d+)',\n",
    "            r'among\\s+(?:them|the\\s+(?:victims?|casualties))\\s+(\\d+)\\s+civilians?',\n",
    "            r'(\\d+)\\s+civilians?\\s+(?:were\\s+)?(?:affected|targeted|hit)',\n",
    "            r'(\\d+)\\s+non-combatants?\\s+(?:killed|injured|wounded)',\n",
    "            r'civilian\\s+toll\\s*:?\\s*(\\d+)',\n",
    "            r'including\\s+(\\d+)\\s+civilians?'\n",
    "        ]\n",
    "        \n",
    "        for pattern in civilian_patterns:\n",
    "            matches = re.findall(pattern, text_lower)\n",
    "            if matches:\n",
    "                try:\n",
    "                    civilians = int(matches[0])\n",
    "                    if 1 <= civilians <= 2000:\n",
    "                        extraction['civilian_casualties'] = civilians\n",
    "                        break\n",
    "                except (ValueError, TypeError):\n",
    "                    continue\n",
    "\n",
    "        # 8. Property damage\n",
    "        damage_types = []\n",
    "        damage_patterns = [\n",
    "            (r'\\bpower\\s+(?:stations?|grid|lines?|infrastructure)', 'power stations'),\n",
    "            (r'\\bhospitals?\\b', 'hospitals'),\n",
    "            (r'\\bschools?\\b', 'schools'),\n",
    "            (r'\\bbridges?\\b', 'bridges'),\n",
    "            (r'\\bbuildings?\\s+(?:damaged|destroyed|collapsed)', 'buildings'),\n",
    "            (r'\\binfrastructure\\s+(?:damaged|destroyed)', 'infrastructure'),\n",
    "            (r'\\bfacilities?\\s+(?:damaged|destroyed)', 'facilities'),\n",
    "            (r'\\broads?\\s+(?:damaged|blocked)', 'roads'),\n",
    "            (r'\\bvehicles?\\s+(?:damaged|destroyed)', 'vehicles'),\n",
    "            (r'\\bequipment\\s+(?:damaged|destroyed)', 'equipment'),\n",
    "            (r'\\bwarehouses?\\s+(?:damaged|destroyed)', 'warehouses'),\n",
    "            (r'\\benterprises?\\s+(?:damaged|destroyed)', 'enterprises'),\n",
    "            (r'\\badministrative\\s+buildings?', 'administrative buildings'),\n",
    "            (r'\\bpetrol\\s+stations?', 'petrol stations'),\n",
    "            (r'\\bresidential\\s+buildings?', 'residential buildings'),\n",
    "            (r'\\bhouses?\\s+(?:damaged|destroyed)', 'houses'),\n",
    "            (r'\\bsocial\\s+facilit(?:y|ies)', 'social facilities'),\n",
    "            (r'\\bminibus(?:es)?\\s+(?:damaged|destroyed)', 'minibuses'),\n",
    "            (r'\\bagricultural\\s+(?:enterprise|equipment)', 'agricultural facilities'),\n",
    "            (r'\\bgarages?\\s+(?:damaged|destroyed)', 'garages'),\n",
    "            (r'\\bhotels?\\s+(?:damaged|destroyed)', 'hotels'),\n",
    "            (r'\\beducational\\s+facilit(?:y|ies)', 'educational facilities'),\n",
    "            (r'\\bmedical\\s+facilit(?:y|ies)', 'medical facilities'),\n",
    "            (r'\\bshops?\\s+(?:damaged|destroyed)', 'shops'),\n",
    "            (r'\\bmotorcycles?\\s+(?:damaged|destroyed)', 'motorcycles'),\n",
    "            (r'\\bsatellite\\s+terminals?', 'satellite terminals'),\n",
    "            (r'\\belectronic\\s+warfare\\s+stations?', 'electronic warfare stations'),\n",
    "            (r'\\bboats?\\s+(?:damaged|destroyed)', 'boats'),\n",
    "            (r'\\buav\\s+(?:control\\s+point|antenna)', 'UAV equipment'),\n",
    "            (r'\\bother\\s+equipment', 'other equipment')\n",
    "        ]\n",
    "        \n",
    "        for pattern, damage_type in damage_patterns:\n",
    "            if re.search(pattern, text_lower):\n",
    "                damage_types.append(damage_type)\n",
    "        \n",
    "        # General damage indicators\n",
    "        general_damage_patterns = [\n",
    "            r'\\bdamaged?\\b', r'\\bdestroyed?\\b', r'\\bcollapsed?\\b',\n",
    "            r'\\bdemolished?\\b', r'\\bruined?\\b', r'\\bwrecked?\\b',\n",
    "        ]\n",
    "        \n",
    "        has_general_damage = any(re.search(pattern, text_lower) for pattern in general_damage_patterns)\n",
    "        \n",
    "        if damage_types:\n",
    "            extraction['property_damage'] = \"yes - \" + \", \".join(damage_types[:4])\n",
    "        elif has_general_damage:\n",
    "            extraction['property_damage'] = \"yes\"\n",
    "        else:\n",
    "            extraction['property_damage'] = \"no\"\n",
    "\n",
    "        # 9. Weapons detection\n",
    "        weapons_patterns = [\n",
    "            # MODERN WEAPONS (highest priority)\n",
    "            (r'\\bbomber[-\\s]?drones?\\b', 'bomber drones'),\n",
    "            (r'\\bshahed[-\\s]?drones?\\b', 'Shahed drones'),\n",
    "            (r'\\bhimars\\b', 'HIMARS'),\n",
    "            (r'\\btornado\\s+mlrs\\b', 'Tornado MLRS'),\n",
    "            (r'\\bmissile\\s+grom[-\\s]?1e\\b', 'Grom-1e missiles'),\n",
    "            (r'\\bmolnia[-\\s]?drones?\\b', 'Molnia drones'),\n",
    "            (r'\\blancet[-\\s]?drones?\\b', 'Lancet drones'),\n",
    "            (r'\\buragan\\s+mlrs\\b', 'Uragan MLRS'),\n",
    "            (r'\\bjavelin\\b', 'Javelin'),\n",
    "            (r'\\bnlaw\\b', 'NLAW'),\n",
    "            (r'\\bcarl[-\\s]?gustaf\\b', 'Carl Gustaf'),\n",
    "            (r'\\buav\\s+supercam\\b', 'UAV SuperCam'),\n",
    "            (r'\\bkab(?:s)?\\s+bombs?\\b', 'KAB bombs'),\n",
    "            (r'\\biskander[-\\s]?m\\s+missiles?\\b', 'Iskander-M missiles'),\n",
    "            (r'\\bfab[-\\s]?\\d*\\s+(?:aerial\\s+)?bombs?', 'FAB aerial bombs'),\n",
    "            (r'\\bfpv\\s+drones?', 'FPV drones'),\n",
    "            (r'\\bkamikaze\\s+drones?', 'kamikaze drones'),\n",
    "            (r'\\bguided\\s+(?:bombs?|missiles?)', 'guided munitions'),\n",
    "            \n",
    "            # AIRCRAFT AND VEHICLES\n",
    "            (r'\\bsu[-\\s]?30\\s+fighter\\s+jets?\\b', 'Su-30 fighter jets'),\n",
    "            (r'\\bsu[-\\s]?25\\s+fighter\\s+jets?\\b', 'Su-25 fighter jets'),\n",
    "            (r'\\bmi[-\\s]?8\\s+helicopters?\\b', 'Mi-8 helicopters'),\n",
    "            (r'\\bmi[-\\s]?26\\s+helicopters?\\b', 'Mi-26 helicopters'),\n",
    "            (r'\\bmi[-\\s]?28\\s+helicopters?\\b', 'Mi-28 helicopters'),\n",
    "            (r'\\bka[-\\s]?52\\s+helicopters?\\b', 'Ka-52 helicopters'),\n",
    "            (r'\\bpantsir[-\\s]?s1\\s+(?:self[-\\s]?propelled\\s+)?(?:anti[-\\s]?aircraft\\s+)?systems?\\b', 'Pantsir-S1 systems'),\n",
    "            (r'\\bifv\\b', 'IFV'),\n",
    "            (r'\\btanks?\\b', 'tanks'),\n",
    "            (r'\\bt[-\\s]?72\\s+m1\\b', 'T-72 M1'),\n",
    "            (r'\\bt[-\\s]?72\\s+m3\\b', 'T-72 M3'),\n",
    "            (r'\\bt[-\\s]?80\\b', 'T-80'),\n",
    "            (r'\\bt[-\\s]?90\\b', 'T-90'),\n",
    "            (r'\\bbmp[-\\s]?2\\b', 'BMP-2'),\n",
    "            (r'\\bbtr[-\\s]?80\\b', 'BTR-80'),\n",
    "            (r'\\bmt[-\\s]?lb\\b', 'MT-LB'),\n",
    "            (r'\\bmig[-\\s]?29\\b', 'MiG-29'),\n",
    "            (r'\\babrams\\s+tanks?\\b', 'Abrams tanks'),\n",
    "            (r'\\bm1\\s+abrams\\b', 'M1 Abrams'),\n",
    "            (r'\\bmlrs\\b', 'MLRS'),\n",
    "            (r'\\bgmars\\b', 'GMARS'),\n",
    "            (r'\\bhelicopters?\\b', 'helicopters'),\n",
    "            (r'\\bjets?\\b', 'jets'),\n",
    "            \n",
    "            # ARTILLERY AND CONVENTIONAL\n",
    "            (r'\\bartillery\\s+shells?\\b', 'artillery shells'),\n",
    "            (r'\\bbarrel\\s+artillery\\b', 'barrel artillery'),\n",
    "            (r'\\b152\\s*mm\\s+(?:gun|artillery)\\b', '152mm artillery'),\n",
    "            (r'\\b122\\s*mm\\s+artillery\\b', '122mm artillery'),\n",
    "            (r'\\b82\\s*mm\\s+mortars?\\b', '82mm mortars'),\n",
    "            (r'\\bunguided\\s+air[-\\s]?launched\\s+missiles?\\b', 'unguided air-launched missiles'),\n",
    "            (r'\\bant[-\\s]?tank[-\\s]?guided\\s+missiles?\\b', 'anti-tank guided missiles'),\n",
    "            (r'\\banti[-\\s]?tank\\s+weapons?\\b', 'anti-tank weapons'),\n",
    "            (r'\\bgrad\\s+bm[-\\s]?21\\s+missiles?\\b', 'Grad BM-21 missiles'),\n",
    "            (r'\\bgrenade\\s+launchers?\\b', 'grenade launchers'),\n",
    "            (r'\\brpgs?\\b', 'RPGs'),\n",
    "            (r'\\bunidentified\\s+weapons?\\s+systems?\\b', 'unidentified weapon systems'),\n",
    "            (r'\\bunspecified\\s+weapons?\\b', 'unspecified weapons'),\n",
    "            (r'\\b120\\s*mm\\s+mortars?\\b', '120mm mortars'),\n",
    "            \n",
    "            # GENERIC PATTERNS\n",
    "            (r'\\bmissiles?\\b', 'missiles'),\n",
    "            (r'\\bartillery\\b', 'artillery'),\n",
    "            (r'\\bmortars?\\b', 'mortars'),\n",
    "            (r'\\bmachine\\s+guns?', 'machine guns'),\n",
    "            (r'\\brifles?\\b', 'rifles'),\n",
    "            (r'\\bgrenade(?:s)?\\b', 'grenades'),\n",
    "            (r'\\bexplosive(?:s)?\\b', 'explosives'),\n",
    "            (r'\\bbombs?\\b', 'bombs'),\n",
    "            (r'\\brockets?\\b', 'rockets'),\n",
    "            (r'\\barmoured\\s+vehicles?', 'armored vehicles'),\n",
    "            (r'\\bdrones?\\b', 'drones')\n",
    "        ]\n",
    "        \n",
    "        weapons_found = []\n",
    "        for pattern, weapon in weapons_patterns:\n",
    "            matches = re.finditer(pattern, text_lower, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                try:\n",
    "                    weapon_name = weapon(match) if callable(weapon) else weapon\n",
    "                    if weapon_name and isinstance(weapon_name, str) and len(weapon_name.strip()) >= 3:\n",
    "                        weapon_name = weapon_name.strip()\n",
    "                        if not any(existing.lower() in weapon_name.lower() or weapon_name.lower() in existing.lower() \n",
    "                                   for existing in weapons_found):\n",
    "                            weapons_found.append(weapon_name)\n",
    "                            if len(weapons_found) >= 6:\n",
    "                                break\n",
    "                except Exception:\n",
    "                    continue\n",
    "            if len(weapons_found) >= 6:\n",
    "                break\n",
    "        \n",
    "        if weapons_found:\n",
    "            extraction['weapons_mentioned'] = weapons_found\n",
    "\n",
    "        # 10. Casualty type\n",
    "        casualty_type = \"unknown\"\n",
    "        casualty_type_patterns = [\n",
    "            ('killed', [r'\\bkilled\\b', r'\\bdeaths?\\b', r'\\bfatalities\\b', r'\\bdied\\b', r'\\bslain\\b']),\n",
    "            ('injured', [r'\\binjured\\b', r'\\bwounded\\b', r'\\bhurt\\b', r'\\bharmed\\b']),\n",
    "            ('missing', [r'\\bmissing\\b', r'\\bdisappeared\\b', r'\\bunaccounted\\s+for\\b']),\n",
    "            ('captured', [r'\\bcaptured\\b', r'\\barrested\\b', r'\\bdetained\\b', r'\\bapprehended\\b']),\n",
    "        ]\n",
    "        \n",
    "        for casualty_cat, patterns in casualty_type_patterns:\n",
    "            if any(re.search(pattern, text_lower) for pattern in patterns):\n",
    "                casualty_type = casualty_cat\n",
    "                break\n",
    "        \n",
    "        extraction['casualty_type'] = casualty_type\n",
    "\n",
    "        # 11. Attack method\n",
    "        attack_method = \"unknown\"\n",
    "        attack_method_patterns = [\n",
    "            ('airstrike', [r'\\bair\\s*strikes?', r'\\bairstrike(?:s)?', r'\\baerial\\s+(?:attack|bombardment)', r'\\bfab.*?bombs?']),\n",
    "            ('artillery_fire', [r'\\bartillery\\s+fire', r'\\bshelling\\b', r'\\bmortars?\\s+fire', r'\\bmortars?\\b']),\n",
    "            ('missile_attack', [r'\\bmissile\\s+(?:attack|strike)', r'\\bmissiles?\\s+(?:fired|launched)']),\n",
    "            ('drone_attack', [\n",
    "                r'\\bukrainian\\s+drones?\\s+struck', r'\\bdrones?\\s+struck\\b', \n",
    "                r'\\bdrone\\s+(?:attack|strike|bombing)', r'\\buav\\s+(?:attack|strike)', \n",
    "                r'\\bunmanned.*?(?:attack|strike)', r'\\bdrone\\s+strikes?\\b'\n",
    "            ]),\n",
    "            ('ground_assault', [r'\\bground\\s+(?:assault|attack)', r'\\binfantry\\s+(?:attack|assault)']),\n",
    "            ('small_arms_fire', [r'\\bsmall\\s+arms', r'\\brifle\\s+fire', r'\\bmachine\\s+gun']),\n",
    "            ('bombing', [r'\\bbombing\\b', r'\\bexplosive\\s+device', r'\\bcar\\s+bomb']),\n",
    "            ('shot_down', [r'\\bshot\\s+down\\b']),\n",
    "            ('shelled', [r'\\bshelled\\b']),\n",
    "            ('incapacitated', [r'\\bincapacitated\\b']),\n",
    "            ('clashed', [r'\\bclashed\\b'])\n",
    "        ]\n",
    "        \n",
    "        for method_cat, patterns in attack_method_patterns:\n",
    "            if any(re.search(pattern, text_lower) for pattern in patterns):\n",
    "                attack_method = method_cat\n",
    "                break\n",
    "        \n",
    "        extraction['attack_method'] = attack_method\n",
    "\n",
    "        # 12. Disorder Type Classification\n",
    "        def classify_disorder_type(text_lower, actor_1, actor_2, event_type):\n",
    "            # Interstate conflict (Highest Priority)\n",
    "            if (('russian military' in actor_1.lower() and 'ukrainian' in actor_2.lower()) or \n",
    "                ('ukrainian military' in actor_1.lower() and 'russian' in actor_2.lower()) or\n",
    "                ('russian military' in text_lower and extraction.get('country') == 'ukraine') or\n",
    "                ('ukrainian' in text_lower and extraction.get('country') == 'russia') or\n",
    "                ('russian forces' in text_lower and extraction.get('country') == 'ukraine') or\n",
    "                ('ukrainian forces' in text_lower and extraction.get('country') == 'russia') or\n",
    "                ('airstrike' in text_lower and (('russian' in text_lower and extraction.get('country') == 'ukraine') or \n",
    "                                               ('ukrainian' in text_lower and extraction.get('country') == 'russia')))):\n",
    "                return 'interstate_conflict'\n",
    "            \n",
    "            # Cross-border operations detection (Second Highest Priority)\n",
    "            if any(term in text_lower for term in ['airstrike', 'bombing', 'missile', 'drone attack']):\n",
    "                if (('russian' in text_lower and extraction.get('country') == 'ukraine') or \n",
    "                    ('ukrainian' in text_lower and extraction.get('country') == 'russia')):\n",
    "                    return 'interstate_conflict'\n",
    "\n",
    "            # Military vs Military or Military vs Forces = armed conflict (Third Highest Priority)\n",
    "            if (('military' in actor_1.lower() and 'military' in actor_2.lower()) or\n",
    "                ('forces' in actor_1.lower() and 'forces' in actor_2.lower())):\n",
    "                return 'armed_conflict'\n",
    "            \n",
    "            # Specific disorder patterns\n",
    "            disorder_patterns = [\n",
    "                # SPECIFIC ethnic patterns\n",
    "                ('interstate_conflict', [\n",
    "                    r'\\bcross[-\\s]border\\s+(?:attack|incident|conflict|operation)\\b',\n",
    "                    r'\\b(?:russian|ukrainian)\\s+forces?\\s+(?:carried\\s+out|conducted|launched)\\s+(?:strikes?|attacks?)',\n",
    "                    r'\\bmilitary\\s+intervention\\b',\n",
    "                    r'\\binvasion\\b'\n",
    "                ]),\n",
    "                ('ethnic_conflict', [\n",
    "                    r'\\bethnic\\s+tensions?\\s+escalated\\s+into\\s+violence',\n",
    "                    r'\\bethnic\\s+(?:conflict|violence|cleansing|war)\\b',\n",
    "                    r'\\brace\\s+(?:riots?|violence|tensions?)\\b',\n",
    "                    # Only classify as ethnic if it's clearly civilian ethnic tension, not military\n",
    "                    r'\\bminority\\s+communities\\s+clashed\\b(?!.*(?:military|forces|troops))'\n",
    "                ]),\n",
    "                ('protest_event', [\n",
    "                    r'\\bpeaceful\\s+protest\\b',\n",
    "                    r'\\bdemonstrators?\\s+gathered\\b',\n",
    "                    r'\\bprotesters?\\s+marched\\b',\n",
    "                    r'\\bactivist(?:s)?\\s+(?:organized|demonstrated|protested)',\n",
    "                    r'\\bstudent\\s+protests?\\b',\n",
    "                    # Only classify as protest if it does not involve military or armed conflict\n",
    "                    r'(?=.*\\bdemonstration(?:s)?\\b)(?!.*(?:military|forces|airstrike|bombing|missile))'\n",
    "                ]),\n",
    "                ('civil_unrest', [\n",
    "                    r'\\briot(?:s)?\\b',\n",
    "                    r'\\bunrest\\b',\n",
    "                    r'\\bmob\\s+violence\\b',\n",
    "                    r'\\bviolent\\s+(?:protest|demonstration)\\b'\n",
    "                ]),\n",
    "                ('separatist_conflict', [\n",
    "                    r'\\bseparatist(?:s)?\\b',\n",
    "                    r'\\bnaf\\s+forces?',\n",
    "                    r'\\brebel\\s+forces?',\n",
    "                    r'\\bbreakaway\\s+region',\n",
    "                    r'\\btransnistrian\\b'\n",
    "                ])\n",
    "            ]\n",
    "            \n",
    "            for disorder_type, patterns in disorder_patterns:\n",
    "                if any(re.search(pattern, text_lower) for pattern in patterns):\n",
    "                    return disorder_type\n",
    "            \n",
    "            return 'unknown'     \n",
    "        \n",
    "        actor_1_val = extraction.get('actor_1', 'unknown')\n",
    "        actor_2_val = extraction.get('actor_2', 'unknown')\n",
    "        disorder_type = classify_disorder_type(text_lower, actor_1_val, actor_2_val, extraction.get('event_type'))\n",
    "        extraction['disorder_type'] = disorder_type\n",
    "\n",
    "        # 13. Infrastructure Detection\n",
    "        infrastructure_patterns = [\n",
    "            ('power_grid', [\n",
    "                r'\\bpower\\s+stations?\\b', \n",
    "                r'\\bpower\\s+(?:outage|grid|supply|lines?|infrastructure)\\b',\n",
    "                r'\\belectricity\\s+(?:supply|infrastructure|outage|grid)\\b',\n",
    "                r'\\benergy\\s+(?:infrastructure|facilities?)\\b',\n",
    "                r'\\belectrical\\s+(?:grid|infrastructure|systems?)\\b',\n",
    "                r'\\bpower\\s+substations?\\b'\n",
    "            ]),\n",
    "            \n",
    "            ('medical_services', [\n",
    "                r'\\bhospitals?\\b',\n",
    "                r'\\bmedical\\s+(?:services|facilities?|centers?)\\b',\n",
    "                r'\\bhealthcare\\s+(?:services|facilities?|infrastructure)\\b',\n",
    "                r'\\bclinics?\\b',\n",
    "                r'\\bmedical\\s+emergency\\s+services?\\b'\n",
    "            ]),\n",
    "            \n",
    "            ('transportation', [\n",
    "                r'\\btransportation\\s+(?:infrastructure|services)\\b',\n",
    "                r'\\b(?:roads?|highways?|bridges?)\\s+(?:blocked|damaged|destroyed)\\b',\n",
    "                r'\\brailways?\\s+(?:damaged|blocked|disrupted)\\b',\n",
    "                r'\\bairports?\\s+(?:closed|damaged)\\b',\n",
    "                r'\\bbridges?\\b'\n",
    "            ]),\n",
    "            \n",
    "            ('communications', [\n",
    "                r'\\bcommunications?\\s+(?:infrastructure|services|disrupted)\\b',\n",
    "                r'\\binternet\\s+(?:services|outage|down)\\b',\n",
    "                r'\\bphone\\s+(?:services|lines|networks?)\\s+(?:down|disrupted)\\b',\n",
    "                r'\\btelecommunications?\\b'\n",
    "            ]),\n",
    "            \n",
    "            ('water_supply', [\n",
    "                r'\\bwater\\s+(?:supply|infrastructure|services|shortage)\\b',\n",
    "                r'\\bwater\\s+treatment\\s+(?:plants?|facilities?)\\b',\n",
    "                r'\\bdrinking\\s+water\\s+(?:shortage|contamination)\\b'\n",
    "            ]),\n",
    "            \n",
    "            ('educational_institutions', [\n",
    "                r'\\bschools?\\s+(?:closed|damaged|evacuated|hit|targeted|destroyed)\\b',\n",
    "                r'\\buniversit(?:y|ies)\\s+(?:closed|damaged|evacuated)\\b',\n",
    "                r'\\beducational\\s+(?:facilities?|institutions?)\\b'\n",
    "            ]),\n",
    "            \n",
    "            ('energy_facilities', [\n",
    "                r'\\boil\\s+depots?\\b',\n",
    "                r'\\bfuel\\s+(?:storage|depot|facility)',\n",
    "                r'\\benergy\\s+(?:facilities|infrastructure)',\n",
    "                r'\\brefinery\\b',\n",
    "                r'\\bgas\\s+pipelines?\\b'\n",
    "            ]),\n",
    "\n",
    "            ('military_infrastructure', [\n",
    "                r'\\bmilitary\\s+(?:base|facility|installation)',\n",
    "                r'\\bairbase\\b',\n",
    "                r'\\bnaval\\s+base',\n",
    "                r'\\bcommand\\s+center',\n",
    "                r'\\bmilitary[-\\s]?industrial\\s+(?:optics\\s+)?plants?\\b',\n",
    "                r'\\bwarhead\\s+plants?\\b',\n",
    "                r'\\bchemical\\s+plants?\\b',\n",
    "                r'\\bindustrial\\s+facilities?\\b',\n",
    "                r'\\bmetal\\s+processing\\s+facilities?\\b',\n",
    "                r'\\bnebo[-\\s]?m\\s+military\\s+radars?\\b',\n",
    "                r'\\bdugouts?\\s+(?:destroyed|damaged)\\b'\n",
    "            ])\n",
    "        ]\n",
    "        \n",
    "        detected_infrastructure = []\n",
    "        for infra_type, patterns in infrastructure_patterns:\n",
    "            if any(re.search(pattern, text_lower) for pattern in patterns):\n",
    "                if infra_type not in detected_infrastructure:\n",
    "                    detected_infrastructure.append(infra_type)\n",
    "        \n",
    "        extraction['infrastructure_disruption'] = detected_infrastructure if detected_infrastructure else \"unknown\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extraction for text '{text[:50]}': {e}\")\n",
    "\n",
    "    # Ensure all required fields are present\n",
    "    for field in required_fields:\n",
    "        if field not in extraction:\n",
    "            extraction[field] = \"unknown\"\n",
    "\n",
    "    return extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation System\n",
    "\n",
    "The validation module applies quality controls to extracted fields, combining rule-based checks with contextual analysis to ensure consistency and reliability before model fine-tuning.\n",
    "\n",
    "### Multi-Stage Validation Process\n",
    "\n",
    "#### Field Integrity Checks\n",
    "\n",
    "- **Presence validation**: All fourteen required fields must exist or be set to `unknown`\n",
    "- **Type consistency**: Confirms correct data types for numeric attributes such as `fatalities` and `civilian_casualties`\n",
    "- **Range validation**: Applies realistic bounds for casualty figures (0–5.000), adjusted for large-scale conflicts\n",
    "\n",
    "#### Geographic and Actor Quality Control\n",
    "\n",
    "- **Location filtering**: Removes 60+ common false positives, including institutional names, temporal references, and generic terms\n",
    "- **Actor validation**: Requires meaningful actor labels that meet minimum length and specificity criteria\n",
    "- **Country-context consistency**: Verifies geographic relationships and cross-border attributions\n",
    "\n",
    "#### Content-Quality Assessment\n",
    "\n",
    "- **Weapons validation**: Excludes invalid weapon mentions while preserving genuine military equipment\n",
    "- **Infrastructure logic**: Confirms that disruption reports align with recorded damage categories\n",
    "\n",
    "### Validation Criteria and Quality Thresholds\n",
    "\n",
    "- **Critical-field enforcement**: `country` and `event_type` must be extracted successfully\n",
    "- **Minimum validity requirements**: Notes must contain at least three valid fields and exceed fifty characters\n",
    "- **Blocking issues**: Critical field failures and severe data inconsistencies prevent sample acceptance\n",
    "- **Error categorisation**: Structured tracking for missing fields, invalid values, and quality concerns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_extraction(sample, required_fields, verbose=False):\n",
    "    \"\"\"\n",
    "    Validation system with checks for missing fields, invalid values, geographic errors, low quality, and critical issues.\n",
    "    Returns: (is_valid, issue_dict)\n",
    "    \"\"\"\n",
    "    issues = {\n",
    "        'missing_fields': [],\n",
    "        'invalid_values': [],\n",
    "        'geographic_errors': [],\n",
    "        'low_quality': [],\n",
    "        'critical': []\n",
    "    }\n",
    "\n",
    "    text = sample['note'].lower()\n",
    "    extraction = sample['extraction']\n",
    "    \n",
    "    # Field validation - ensure all required fields exist\n",
    "    for field in required_fields:\n",
    "        if field not in extraction:\n",
    "            issues['missing_fields'].append(field)\n",
    "            extraction[field] = \"unknown\"\n",
    "\n",
    "    # Location validation\n",
    "    if 'location' in extraction and extraction['location'] != \"unknown\":\n",
    "        locations = extraction['location']\n",
    "        if isinstance(locations, list):\n",
    "            invalid_locs = []\n",
    "            bad_words = [\n",
    "                'according', 'russian', 'ukrainian', 'government', 'forces', 'military', \n",
    "                'police', 'national', 'state', 'public', 'local', 'regional', 'federal',\n",
    "                'armed', 'security', 'border', 'emergency', 'special', 'international',\n",
    "                'president', 'minister', 'official', 'today', 'yesterday', 'morning'\n",
    "            ]\n",
    "            for loc in locations:\n",
    "                if (not isinstance(loc, str) or \n",
    "                    loc.lower() in bad_words or \n",
    "                    len(loc.strip()) < 2 or\n",
    "                    loc.startswith(('The ', 'And ', 'But ', 'For ', 'With ')) or\n",
    "                    not re.match(r'^[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*$', loc)):\n",
    "                    invalid_locs.append(loc)\n",
    "            if invalid_locs:\n",
    "                issues['invalid_values'].append(f\"Invalid locations: {invalid_locs}\")\n",
    "\n",
    "    # Actor validation\n",
    "    for actor_field in ['actor_1', 'actor_2']:\n",
    "        if actor_field in extraction and extraction[actor_field] != \"unknown\":\n",
    "            actor = extraction[actor_field]\n",
    "            if (isinstance(actor, str) and \n",
    "                (len(actor.strip()) < 4 or \n",
    "                 actor.lower() in ['forces', 'military', 'police', 'government', 'troops', 'unknown'] or\n",
    "                 actor.startswith(('The ', 'the ')))):\n",
    "                issues['invalid_values'].append(f\"Invalid {actor_field}: {actor}\")\n",
    "                extraction[actor_field] = \"unknown\"\n",
    "\n",
    "    # Numeric validation\n",
    "    for field in ['fatalities', 'civilian_casualties']:\n",
    "        if field in extraction and extraction[field] != \"unknown\":\n",
    "            try:\n",
    "                val = int(extraction[field])\n",
    "                if val < 0 or val > 5000:\n",
    "                    issues['invalid_values'].append(f\"Unrealistic {field}: {val}\")\n",
    "                    extraction[field] = \"unknown\"\n",
    "            except (ValueError, TypeError):\n",
    "                issues['invalid_values'].append(f\"Invalid {field} value: {extraction[field]}\")\n",
    "                extraction[field] = \"unknown\"\n",
    "\n",
    "    # Weapons validation\n",
    "    if 'weapons_mentioned' in extraction and extraction['weapons_mentioned'] != \"unknown\":\n",
    "        if isinstance(extraction['weapons_mentioned'], list):\n",
    "            valid_weapons = []\n",
    "            for weapon in extraction['weapons_mentioned']:\n",
    "                if (isinstance(weapon, str) and \n",
    "                    len(str(weapon).strip()) >= 3 and\n",
    "                    not weapon.startswith(('The ', 'the ', 'And ', 'But '))):\n",
    "                    valid_weapons.append(weapon)\n",
    "            if valid_weapons:\n",
    "                extraction['weapons_mentioned'] = valid_weapons\n",
    "            else:\n",
    "                extraction['weapons_mentioned'] = \"unknown\"\n",
    "\n",
    "    # Infrastructure validation\n",
    "    if 'infrastructure_disruption' in extraction and extraction['infrastructure_disruption'] != \"unknown\":\n",
    "        if isinstance(extraction['infrastructure_disruption'], list):\n",
    "            valid_infra = [\n",
    "                'power_grid', 'medical_services', 'transportation', 'communications', \n",
    "                'water_supply', 'educational_institutions', 'energy_facilities', 'military_infrastructure'\n",
    "            ]\n",
    "            filtered_infra = [infra for infra in extraction['infrastructure_disruption'] if infra in valid_infra]\n",
    "            if not filtered_infra:\n",
    "                extraction['infrastructure_disruption'] = \"unknown\"\n",
    "            else:\n",
    "                extraction['infrastructure_disruption'] = filtered_infra\n",
    "\n",
    "    # Critical field enforcement\n",
    "    critical_fields = ['country', 'event_type']\n",
    "    for field in critical_fields:\n",
    "        if extraction.get(field) == \"unknown\":\n",
    "            issues['critical'].append(f\"Missing critical field: {field}\")\n",
    "\n",
    "    # Quality thresholds\n",
    "    valid_fields = sum(1 for v in extraction.values() if v != \"unknown\")\n",
    "    if valid_fields < 3:\n",
    "        issues['low_quality'].append(\"Too few fields extracted\")\n",
    "    if len(sample['note']) < 50:\n",
    "        issues['low_quality'].append(\"Note too short for valid extraction\")\n",
    "\n",
    "    # Determine validity\n",
    "    blocking_issues = len(issues['critical']) + len(issues['geographic_errors'])\n",
    "    severe_invalid = [\n",
    "        issue for issue in issues['invalid_values'] \n",
    "        if 'Unrealistic' in issue and 'Potential' not in issue\n",
    "    ]\n",
    "    blocking_issues += len(severe_invalid)\n",
    "    is_valid = blocking_issues == 0 and valid_fields >= 3\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nNote: {sample['note'][:80]}\")\n",
    "        print(f\"Valid fields: {valid_fields}/{len(required_fields)}\")\n",
    "        print(f\"Issues: {sum(len(v) for v in issues.values())} total\")\n",
    "        print(f\"Valid: {is_valid}\")\n",
    "\n",
    "    return is_valid, issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Suite Validation\n",
    "\n",
    "This section introduces an automated testing framework that evaluates extraction accuracy across a wide range of conflict scenarios, including recent events from the Ukraine–Russia war and other, smaller, Eastern-European security incidents.\n",
    "\n",
    "### Test-coverage scope\n",
    "\n",
    "#### Modern conflict scenarios\n",
    "- **Aerial operations**: Russian air strikes using guided missiles on Ukrainian territory.  \n",
    "- **Cross-border operations**: Ukrainian drone strikes in Russia’s Belgorod region.  \n",
    "- **Infrastructure targeting**: Attacks on power stations and medical facilities that disrupt essential services.  \n",
    "- **Multi-actor conflicts**: NAF rebel forces engaging Ukrainian troops with specified weaponry.  \n",
    "\n",
    "#### Geographic-diversity testing\n",
    "- **Thirteen-country coverage**: Cases drawn from from target states.\n",
    "- **Urban v regional**: Major cities (Kyiv, Warsaw) and smaller localities (Kostiantynivka, Belgorod).  \n",
    "- **Cross-border attribution**: Checks correct country assignment for international operations.  \n",
    "\n",
    "#### Edge cases and robustness\n",
    "- **Minimal information**: Ensures graceful degradation when reports are brief.  \n",
    "- **Complex actor relationships**: Validates detection of multiple interacting forces.  \n",
    "- **Infrastructure specificity**: Confirms detailed damage classification by category.\n",
    "\n",
    "### Validation metrics and performance\n",
    "\n",
    "| Metric | Result |\n",
    "| --- | --- |\n",
    "| **Individual-field accuracy** | 100% |\n",
    "| **Complete-case success** | 5 / 5 — 100% of tests achieve full field extraction |\n",
    "| **Country coverage** | 100% correct geographic attribution |\n",
    "| **Robustness** | Consistent `unknown` fallback where data are missing |\n",
    "\n",
    "### Success-criteria assessment\n",
    "\n",
    "- **Status**: **Excellent** – the extractor performs reliably across varied conflict scenarios.  \n",
    "- **Readiness**: Approved for large-scale dataset processing with **robust** error handling.  \n",
    "- **Quality assurance**: Systematic validation of critical fields, including actor detection, weapons identification, and infrastructure assessment.  \n",
    "\n",
    "### Test Results\n",
    "\n",
    "| Metric | Result |\n",
    "| --- | --- |\n",
    "| Individual tests passed | 36 / 36 (100.0%) |\n",
    "| Complete cases passed | 5 / 5 (100.0%) |\n",
    "| Validation passed | 5 / 5 (100.0%) |\n",
    "\n",
    "- **Overall status**: **EXCELLENT (100.0%)**  \n",
    "- **System ready for production**: **True**  \n",
    "- **Robustness**: Consistent `unknown` fallback verified  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXTRACTION FUNCTION TEST SUITE\n",
      "============================================================\n",
      "\n",
      "Test Case: russian_airstrike_ukraine\n",
      "Note: Russian forces launched air strikes with guided missiles on Kostiantynivka on 10 May 2024, killing 3 people and damaging power stations and hospitals.\n",
      "  Validation result: PASS\n",
      "  event_date: PASS (10 May 2024)\n",
      "  country: PASS (ukraine)\n",
      "  location includes ['Kostiantynivka']: PASS\n",
      "  actor_1: PASS (Russian military forces)\n",
      "  fatalities: PASS (3)\n",
      "  weapons_mentioned includes ['guided munitions', 'missiles']: PASS\n",
      "  property_damage includes ['power stations', 'hospitals']: PASS\n",
      "  infrastructure_disruption includes ['power_grid', 'medical_services']: PASS\n",
      "  attack_method: PASS (airstrike)\n",
      "  event_type: PASS (remote_violence)\n",
      "\n",
      "Test Case: ukraine_drone_belgorod\n",
      "Note: Ukrainian military forces launched drone attacks against Russian military positions in Belgorod region, disrupting power grid infrastructure.\n",
      "  Validation result: PASS\n",
      "  country: PASS (russia)\n",
      "  location includes ['Belgorod']: PASS\n",
      "  actor_1: PASS (Ukrainian military forces)\n",
      "  actor_2: PASS (Russian military forces)\n",
      "  weapons_mentioned includes ['drones']: PASS\n",
      "  infrastructure_disruption includes ['power_grid']: PASS\n",
      "  attack_method: PASS (drone_attack)\n",
      "  disorder_type: PASS (interstate_conflict)\n",
      "\n",
      "Test Case: naf_ukrainian_engagement\n",
      "Note: NAF rebel forces fired with 120mm mortars at Ukrainian military forces positioned in Donetsk region. 3 Ukrainian soldiers were injured.\n",
      "  Validation result: PASS\n",
      "  country: PASS (ukraine)\n",
      "  location includes ['Donetsk']: PASS\n",
      "  actor_1: PASS (NAF rebel forces)\n",
      "  actor_2: PASS (Ukrainian military forces)\n",
      "  weapons_mentioned includes ['120mm mortars']: PASS\n",
      "  casualty_type: PASS (injured)\n",
      "  attack_method: PASS (artillery_fire)\n",
      "\n",
      "Test Case: warsaw_protest_scenario\n",
      "Note: Protesters gathered in Warsaw to call for government reforms. The police forces dispersed the demonstration and arrested several activists.\n",
      "  Validation result: PASS\n",
      "  country: PASS (poland)\n",
      "  location includes ['Warsaw']: PASS\n",
      "  actor_1: PASS (protesters)\n",
      "  actor_2: PASS (police forces)\n",
      "  event_type: PASS (protests)\n",
      "  casualty_type: PASS (captured)\n",
      "  disorder_type: PASS (protest_event)\n",
      "\n",
      "Test Case: minimal_information_test\n",
      "Note: Security incident reported in Kyiv on 15 March 2024. Military forces responded to the situation.\n",
      "  Validation result: PASS\n",
      "  event_date: PASS (15 March 2024)\n",
      "  country: PASS (ukraine)\n",
      "  location includes ['Kyiv']: PASS\n",
      "  actor_1: PASS (military forces)\n",
      "\n",
      "============================================================\n",
      "TEST RESULTS\n",
      "============================================================\n",
      "Individual tests passed: 36/36 (100.0%)\n",
      "Complete cases passed: 5/5 (100.0%)\n",
      "Validation passed: 5/5 (100.0%)\n",
      "\n",
      "Overall status: EXCELLENT (100.0%)\n",
      "System ready for production: True\n",
      "Robustness: Consistent unknown fallback verified\n",
      "\n",
      "Extraction system validation complete. Ready for deployment: True\n"
     ]
    }
   ],
   "source": [
    "def run_extraction_tests():\n",
    "    \"\"\"Test suite evaluating extraction accuracy across varied conflict scenarios.\"\"\"\n",
    "    \n",
    "    print(\"EXTRACTION FUNCTION TEST SUITE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    test_cases = [\n",
    "        {\n",
    "            'ID': 'russian_airstrike_ukraine',\n",
    "            'note': \"Russian forces launched air strikes with guided missiles on Kostiantynivka on 10 May 2024, killing 3 people and damaging power stations and hospitals.\",\n",
    "            'expected': {\n",
    "                'event_date': '10 May 2024',\n",
    "                'country': 'ukraine',\n",
    "                'location_includes': ['Kostiantynivka'],\n",
    "                'actor_1': 'Russian military forces',\n",
    "                'fatalities': 3,\n",
    "                'weapons_mentioned_includes': ['guided munitions', 'missiles'],\n",
    "                'property_damage_includes': ['power stations', 'hospitals'],\n",
    "                'infrastructure_disruption_includes': ['power_grid', 'medical_services'],\n",
    "                'attack_method': 'airstrike',\n",
    "                'event_type': 'remote_violence'\n",
    "            }\n",
    "        },\n",
    "\n",
    "        {\n",
    "            'ID': 'ukraine_drone_belgorod',\n",
    "            'note': \"Ukrainian military forces launched drone attacks against Russian military positions in Belgorod region, disrupting power grid infrastructure.\",\n",
    "            'expected': {\n",
    "                'country': 'russia',\n",
    "                'location_includes': ['Belgorod'],\n",
    "                'actor_1': 'Ukrainian military forces',\n",
    "                'actor_2': 'Russian military forces',\n",
    "                'weapons_mentioned_includes': ['drones'],\n",
    "                'infrastructure_disruption_includes': ['power_grid'],\n",
    "                'attack_method': 'drone_attack',\n",
    "                'disorder_type': 'interstate_conflict'\n",
    "            }\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            'ID': 'naf_ukrainian_engagement', \n",
    "            'note': \"NAF rebel forces fired with 120mm mortars at Ukrainian military forces positioned in Donetsk region. 3 Ukrainian soldiers were injured.\",\n",
    "            'expected': {\n",
    "                'country': 'ukraine',\n",
    "                'location_includes': ['Donetsk'],\n",
    "                'actor_1': 'NAF rebel forces',\n",
    "                'actor_2': 'Ukrainian military forces',\n",
    "                'weapons_mentioned_includes': ['120mm mortars'],\n",
    "                'casualty_type': 'injured',\n",
    "                'attack_method': 'artillery_fire',\n",
    "            }\n",
    "        },\n",
    "\n",
    "        {\n",
    "            'ID': 'warsaw_protest_scenario',\n",
    "            'note': \"Protesters gathered in Warsaw to call for government reforms. The police forces dispersed the demonstration and arrested several activists.\",\n",
    "            'expected': {\n",
    "                'country': 'poland',\n",
    "                'location_includes': ['Warsaw'],\n",
    "                'actor_1': 'protesters',\n",
    "                'actor_2': 'police forces',\n",
    "                'event_type': 'protests',\n",
    "                'casualty_type': 'captured',\n",
    "                'disorder_type': 'protest_event'\n",
    "            }\n",
    "        },\n",
    "\n",
    "        {\n",
    "            'ID': 'minimal_information_test',\n",
    "            'note': \"Security incident reported in Kyiv on 15 March 2024. Military forces responded to the situation.\",\n",
    "            'expected': {\n",
    "                'event_date': '15 March 2024',\n",
    "                'country': 'ukraine',\n",
    "                'location_includes': ['Kyiv'],\n",
    "                'actor_1': 'military forces'\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    total_checks = 0\n",
    "    passed_checks = 0\n",
    "    \n",
    "    for case in test_cases:\n",
    "        print(f\"\\nTest Case: {case['ID']}\")\n",
    "        print(f\"Note: {case['note']}\")\n",
    "        \n",
    "        extraction = extract_fields(case['note'])\n",
    "        expected = case['expected']\n",
    "        case_passed = True\n",
    "        case_issues = []\n",
    "        \n",
    "        if not isinstance(extraction, dict):\n",
    "            print(f\"  ERROR: extract_fields returned {type(extraction)} instead of dict\")\n",
    "            extraction = {}\n",
    "            case_passed = False\n",
    "        \n",
    "        # Validation\n",
    "        mock_sample = {\n",
    "            'note': case['note'],\n",
    "            'extraction': extraction,\n",
    "            'metadata': {'source_country': 'test'}\n",
    "        }\n",
    "        \n",
    "        is_valid, issues = validate_extraction(mock_sample, TARGET_FIELDS)\n",
    "        print(f\"  Validation result: {'PASS' if is_valid else 'FAIL'}\")\n",
    "        if not is_valid:\n",
    "            total_issue_count = sum(len(v) for v in issues.values())\n",
    "            print(f\"  Issue count: {total_issue_count}\")\n",
    "            if total_issue_count:\n",
    "                for k, v in issues.items():\n",
    "                    if v:\n",
    "                        case_issues.append(f\"{k}: {v}\")\n",
    "        \n",
    "        # Check expectations\n",
    "        for key, expected_val in expected.items():\n",
    "            total_checks += 1\n",
    "            \n",
    "            # Inclusion checks\n",
    "            if key.endswith('_includes'):\n",
    "                base = key.replace('_includes', '')\n",
    "                targets = expected_val if isinstance(expected_val, list) else [expected_val]\n",
    "                actual = extraction.get(base, [])\n",
    "                \n",
    "                if isinstance(actual, list):\n",
    "                    found = []\n",
    "                    for t in targets:\n",
    "                        if any(t.lower() in str(item).lower() for item in actual):\n",
    "                            found.append(t)\n",
    "                    if len(found) == len(targets):\n",
    "                        print(f\"  {base} includes {targets}: PASS\")\n",
    "                        passed_checks += 1\n",
    "                    else:\n",
    "                        missing = [t for t in targets if t not in found]\n",
    "                        print(f\"  {base} includes {targets}: FAIL (missing {missing}, got {actual})\")\n",
    "                        case_passed = False\n",
    "                \n",
    "                elif isinstance(actual, str):\n",
    "                    if all(t.lower() in actual.lower() for t in targets):\n",
    "                        print(f\"  {base} includes {targets}: PASS\")\n",
    "                        passed_checks += 1\n",
    "                    else:\n",
    "                        print(f\"  {base} includes {targets}: FAIL (got {actual})\")\n",
    "                        case_passed = False\n",
    "                else:\n",
    "                    print(f\"  {base} includes {targets}: FAIL (unexpected type {type(actual)})\")\n",
    "                    case_passed = False\n",
    "            \n",
    "            # Direct equality checks\n",
    "            else:\n",
    "                actual_val = extraction.get(key, 'missing')\n",
    "                if actual_val == expected_val:\n",
    "                    print(f\"  {key}: PASS ({actual_val})\")\n",
    "                    passed_checks += 1\n",
    "                else:\n",
    "                    print(f\"  {key}: FAIL (got {actual_val}, expected {expected_val})\")\n",
    "                    case_passed = False\n",
    "        \n",
    "        results.append({\n",
    "            'case_ID': case['ID'],\n",
    "            'passed': case_passed,\n",
    "            'validation_passed': is_valid,\n",
    "            'extraction': extraction,\n",
    "            'issues': case_issues\n",
    "        })\n",
    "    \n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(\"TEST RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    success_rate = (passed_checks / total_checks) * 100 if total_checks > 0 else 0.0\n",
    "    cases_passed = sum(1 for r in results if r['passed'])\n",
    "    case_pass_rate = (cases_passed / len(results)) * 100 if results else 0.0\n",
    "    validation_passed = sum(1 for r in results if r['validation_passed'])\n",
    "    validation_rate = (validation_passed / len(results)) * 100 if results else 0.0\n",
    "    \n",
    "    print(f\"Individual tests passed: {passed_checks}/{total_checks} ({success_rate:.1f}%)\")\n",
    "    print(f\"Complete cases passed: {cases_passed}/{len(results)} ({case_pass_rate:.1f}%)\")\n",
    "    print(f\"Validation passed: {validation_passed}/{len(results)} ({validation_rate:.1f}%)\")\n",
    "    \n",
    "    overall_score = (success_rate + case_pass_rate + validation_rate) / 3 if results else 0.0\n",
    "    if overall_score >= 90:\n",
    "        status = \"EXCELLENT\"\n",
    "        ready = True\n",
    "    elif overall_score >= 80:\n",
    "        status = \"GOOD\"\n",
    "        ready = True\n",
    "    elif overall_score >= 70:\n",
    "        status = \"ACCEPTABLE\"\n",
    "        ready = True\n",
    "    else:\n",
    "        status = \"NEEDS IMPROVEMENT\"\n",
    "        ready = False\n",
    "    \n",
    "    print(f\"\\nOverall status: {status} ({overall_score:.1f}%)\")\n",
    "    print(f\"System ready for production: {ready}\")\n",
    "    print(f\"Robustness: {'Consistent unknown fallback verified' if ready else 'Needs improvement'}\")\n",
    "    \n",
    "    return ready, results\n",
    "\n",
    "test_ready, test_results = run_extraction_tests()\n",
    "print(f\"\\nExtraction system validation complete. Ready for deployment: {test_ready}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Complete: ACLED Subset Ready for Fine-tuning\n",
    "\n",
    "### Processing Results\n",
    "\n",
    "A total of **309.974** raw ACLED conflict-event records were processed and filtered to produce a curated subset of **25.000** high-quality samples, optimised for fine-tuning small language models. The final dataset demonstrates strong coverage across key information fields and balanced geographic representation, particularly within recent conflict zones. This curated subset forms a robust foundation for training lightweight models on structured conflict-event extraction, with a specific focus on Eastern European security dynamics and contemporary warfare reporting.\n",
    "\n",
    "#### Pipeline Performance\n",
    "\n",
    "| Metric | Value |\n",
    "| --- | --- |\n",
    "| **Data throughput** | 309.974 records processed with quality filtering applied |\n",
    "| **Field extraction** | 70.7% passed validation, yielding 219.180 structurally and semantically valid samples |\n",
    "| **Strategic selection** | 25.000 samples selected, averaging 10.8 fields per record |\n",
    "| **Geographic coverage** | 100% country detection accuracy across thirteen nations |\n",
    "\n",
    "#### Delivered Capabilities\n",
    "\n",
    "- **Modern conflict recognition**  \n",
    "  - Classification of interstate and cross-border operations  \n",
    "  - Detection of FPV drones, Shahed drones, HIMARS, and other military assets  \n",
    "  - Secondary-actor targeting detection (e.g. “targeting Ukrainian military personnel”)  \n",
    "  - Infrastructure disruption captured across eight damage categories  \n",
    "\n",
    "- **Quality optimisation**  \n",
    "  - 24.907 samples contain 10 or more extracted fields (99.6% of the subset)  \n",
    "  - No samples contain all fourteen fields, reflecting the realistic sparsity of conflict data  \n",
    "  - Rare and informative field combinations prioritised during curation  \n",
    "  - Validation thresholds aligned to the nature of ACLED reporting  \n",
    "\n",
    "#### Export Details\n",
    "\n",
    "- `ACLED_finetuning_dataset.jsonl` – 25.000 instruction–output pairs in clean JSONL format  \n",
    "- `dataset_metadata.json` – Summary of field coverage, validation metrics, and sampling logic\n",
    "\n",
    "### Dataset Quality Metrics\n",
    "\n",
    "| Aspect | Result |\n",
    "| --- | --- |\n",
    "| **Field coverage** | 10.8 / 14 average fields per sample (≈ 77.1%) |\n",
    "| **Geographic representation** | Ukraine dominant, Russia secondary, with eleven other countries proportionally sampled |\n",
    "| **Temporal range** | 1 January 2018 to 7 July 2025 (capturing evolving conflict patterns) |\n",
    "| **Validation success** | Multi-stage validation ensures high data integrity for fine-tuning |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ACLED DATA PROCESSING PIPELINE\n",
      "======================================================================\n",
      "Processing 309,974 total samples with strict field extraction\n",
      "Target: Create 25.000 high-quality samples for fine-tuning\n",
      "\n",
      "Step 1: Quality Assessment\n",
      "Applying quality thresholds to all samples\n",
      "  Quality assessment: 100,000/309,974 (32.3%)\n",
      "  Quality assessment: 200,000/309,974 (64.5%)\n",
      "  Quality assessment: 300,000/309,974 (96.8%)\n",
      "  Quality assessment: 309,974/309,974 (100.0%)\n",
      " Quality filtering: 309,974/309,974 samples retained (100.0%)\n",
      "\n",
      "Step 2: Field Extraction\n",
      "Processing 309,974 samples\n",
      "Extracted: 50,000/309,974 (16.1%) - Errors: 0\n",
      "Extracted: 100,000/309,974 (32.3%) - Errors: 0\n",
      "Extracted: 150,000/309,974 (48.4%) - Errors: 0\n",
      "Extracted: 200,000/309,974 (64.5%) - Errors: 0\n",
      "Extracted: 250,000/309,974 (80.7%) - Errors: 0\n",
      "Extracted: 300,000/309,974 (96.8%) - Errors: 0\n",
      "Extracted: 309,974/309,974 (100.0%) - Errors: 0\n",
      "Extraction complete: 309,974 samples processed\n",
      "\n",
      "Step 3: Validation\n",
      "Validating 309,974 extracted samples\n",
      "Validation complete: 219,180 valid samples (70.7% success rate)\n",
      "Validation errors: 90,794\n",
      "\n",
      "Step 4: Country Coverage Test\n",
      "  Ukraine: ukraine\n",
      "  Russia: russia\n",
      "  Poland: poland\n",
      "  Czech Republic: czech republic\n",
      "  Hungary: hungary\n",
      "  Slovakia: slovakia\n",
      "  Lithuania: lithuania\n",
      "  Latvia: latvia\n",
      "  Estonia: estonia\n",
      "  Bulgaria: bulgaria\n",
      "  Romania: romania\n",
      "  Belarus: belarus\n",
      "  Moldova: moldova\n",
      "Country coverage: 100.0% accuracy\n",
      "\n",
      "Pipeline complete: Ready for strategic subset creation.\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"ACLED DATA PROCESSING PIPELINE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"Processing {len(df):,} total samples with strict field extraction\")\n",
    "print(f\"Target: Create 25.000 high-quality samples for fine-tuning\")\n",
    "\n",
    "print(f\"\\nStep 1: Quality Assessment\")\n",
    "print(f\"Applying quality thresholds to all samples\")\n",
    "\n",
    "quality_results = []\n",
    "batch_size = 50000\n",
    "total_processed = 0\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch = df.iloc[i:i+batch_size]\n",
    "    \n",
    "    for idx, row in batch.iterrows():\n",
    "        passes_basic, quality_score = assess_note_quality(row['notes'])\n",
    "        quality_results.append((passes_basic, quality_score))\n",
    "    \n",
    "    total_processed += len(batch)\n",
    "    if total_processed % 100000 == 0 or total_processed == len(df):\n",
    "        print(f\"  Quality assessment: {total_processed:,}/{len(df):,} ({total_processed/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Columns\n",
    "df['passes_quality'] = [result[0] for result in quality_results]\n",
    "df['quality_score'] = [result[1] for result in quality_results]\n",
    "\n",
    "# Filter by quality\n",
    "quality_df = df[df['passes_quality'] == True].copy()\n",
    "print(f\" Quality filtering: {len(quality_df):,}/{len(df):,} samples retained ({len(quality_df)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Field extraction\n",
    "print(f\"\\nStep 2: Field Extraction\")\n",
    "print(f\"Processing {len(quality_df):,} samples\")\n",
    "\n",
    "extraction_results = []\n",
    "batch_size = 10000\n",
    "total_processed = 0\n",
    "extraction_errors = 0\n",
    "\n",
    "for i in range(0, len(quality_df), batch_size):\n",
    "    batch = quality_df.iloc[i:i+batch_size]\n",
    "    \n",
    "    for idx, row in batch.iterrows():\n",
    "        try:\n",
    "            extracted = extract_fields(row['notes'])\n",
    "            \n",
    "            sample = {\n",
    "                'original_index': idx,\n",
    "                'note': row['notes'],\n",
    "                'extraction': extracted,\n",
    "                'metadata': {\n",
    "                    'source_country': row['country'],\n",
    "                    'source_date': row['event_date'].isoformat() if pd.notna(row['event_date']) else None,\n",
    "                    'quality_score': row['quality_score']\n",
    "                }\n",
    "            }\n",
    "            extraction_results.append(sample)\n",
    "        except Exception as e:\n",
    "            extraction_errors += 1\n",
    "            if extraction_errors <= 5:\n",
    "                print(f\"Warning: Extraction error for sample {idx}: {str(e)[:100]}\")\n",
    "            continue\n",
    "    \n",
    "    total_processed += len(batch)\n",
    "    if total_processed % 50000 == 0 or total_processed == len(quality_df):\n",
    "        print(f\"Extracted: {total_processed:,}/{len(quality_df):,} ({total_processed/len(quality_df)*100:.1f}%) - Errors: {extraction_errors}\")\n",
    "\n",
    "print(f\"Extraction complete: {len(extraction_results):,} samples processed\")\n",
    "\n",
    "# Validation procedure\n",
    "print(f\"\\nStep 3: Validation\")\n",
    "print(f\"Validating {len(extraction_results):,} extracted samples\")\n",
    "\n",
    "valid_samples = []\n",
    "validation_errors = 0\n",
    "\n",
    "for sample in extraction_results:\n",
    "    try:\n",
    "        is_valid, issues = validate_extraction(sample, TARGET_FIELDS)\n",
    "        if is_valid:\n",
    "            valid_samples.append(sample)\n",
    "        else:\n",
    "            validation_errors += 1\n",
    "    except Exception as e:\n",
    "        validation_errors += 1\n",
    "        continue\n",
    "\n",
    "print(f\"Validation complete: {len(valid_samples):,} valid samples ({len(valid_samples)/len(extraction_results)*100:.1f}% success rate)\")\n",
    "print(f\"Validation errors: {validation_errors:,}\")\n",
    "\n",
    "# Final Step: Country Coverage Test\n",
    "print(f\"\\nStep 4: Country Coverage Test\")\n",
    "test_cases = {\n",
    "    'Ukraine': \"Russian forces attacked Kyiv with missiles\",\n",
    "    'Russia': \"Ukrainian drones struck Belgorod region\", \n",
    "    'Poland': \"Protesters gathered in Warsaw demanding change\",\n",
    "    'Czech Republic': \"Police responded to demonstrations in Prague\",\n",
    "    'Hungary': \"Government forces clashed with protesters in Budapest\",\n",
    "    'Slovakia': \"Military exercises conducted near Bratislava\",\n",
    "    'Lithuania': \"Border incident reported near Vilnius\",\n",
    "    'Latvia': \"Security forces responded to unrest in Riga\", \n",
    "    'Estonia': \"Ethnic tensions escalated in Tallinn\",\n",
    "    'Bulgaria': \"Protests erupted in Sofia over economic policies\",\n",
    "    'Romania': \"Military conducted operations near Bucharest\",\n",
    "    'Belarus': \"Government crackdown on protesters in Minsk\",\n",
    "    'Moldova': \"Separatist forces active in Tiraspol region\"\n",
    "}\n",
    "\n",
    "coverage_results = {}\n",
    "for country, text in test_cases.items():\n",
    "    result = extract_fields(text)\n",
    "    detected_country = result.get('country', 'NOT DETECTED')\n",
    "    coverage_results[country] = detected_country\n",
    "    print(f\"  {country}: {detected_country}\")\n",
    "\n",
    "coverage_success = sum(1 for country, detected in coverage_results.items() \n",
    "                      if detected.lower() == country.lower()) / len(test_cases)\n",
    "print(f\"Country coverage: {coverage_success*100:.1f}% accuracy\")\n",
    "\n",
    "print(f\"\\nPipeline complete: Ready for strategic subset creation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STRATEGIC SUBSET CREATION & EXPORT\n",
      "======================================================================\n",
      "\n",
      "Creating strategic subset from 219,180 valid samples\n",
      "Target: 25,000 samples with maximum field coverage\n",
      "Subset Analysis:\n",
      "Selected: 25,000 samples\n",
      "Average fields per sample: 10.8/14\n",
      "Samples with all 14 fields: 0\n",
      "Samples with ≥10 fields: 24,907\n",
      "\n",
      "Exporting 25,000 samples to clean JSONL format\n",
      "Dataset exported: ACLED_data_export/ACLED_finetuning_dataset.jsonl\n",
      "Metadata exported: ACLED_data_export/dataset_metadata.json\n",
      "\n",
      "Validation Summary:\n",
      "Total samples: 25,000\n",
      "Average fields per sample: 10.8/14\n",
      "Export directory: ACLED_data_export\n",
      "Files created: ACLED_finetuning_dataset.jsonl, dataset_metadata.json\n",
      "\n",
      "Sample entry:\n",
      "ID: acled_00001\n",
      "Fields extracted: 13\n",
      "Instruction: Extract relevant information from this conflict event report:\n",
      "\n",
      "On 8 July 2024, Russian forces launch\n",
      "Output preview:\n",
      "  event_date: 8 July 2024\n",
      "  country: ukraine\n",
      "  location: ['Kyiv', 'Okhmatdyt']\n",
      "  event_type: remote_violence\n",
      "  actor_1: Russian military forces\n",
      "\n",
      "Export complete. Dataset ready for fine-tuning.\n"
     ]
    }
   ],
   "source": [
    "def strategic_subset(samples, target_size=25000):\n",
    "    \"\"\"Strategically selected subset prioritising highest quality notes that cover more than 10 fileds.\"\"\"\n",
    "    \n",
    "    print(f\"\\nCreating strategic subset from {len(samples):,} valid samples\")\n",
    "    print(f\"Target: {target_size:,} samples with maximum field coverage\")\n",
    "    \n",
    "    scored_samples = []\n",
    "    \n",
    "    for sample in samples:\n",
    "        extraction = sample['extraction']\n",
    "        \n",
    "        # Count valid fields\n",
    "        valid_fields = sum(1 for field, value in extraction.items() \n",
    "                          if value != \"unknown\" and field in TARGET_FIELDS)\n",
    "        \n",
    "        # Calculate scores\n",
    "        completeness_score = valid_fields\n",
    "        quality_bonus = sample['metadata']['quality_score'] * 0.5\n",
    "        \n",
    "        # Bonus for rare fields\n",
    "        rare_field_bonus = 0\n",
    "        rare_fields = ['disorder_type', 'infrastructure_disruption', 'civilian_casualties', 'casualty_type']\n",
    "        for field in rare_fields:\n",
    "            if extraction.get(field) != \"unknown\":\n",
    "                rare_field_bonus += 2.0\n",
    "        \n",
    "        total_score = completeness_score + quality_bonus + rare_field_bonus\n",
    "        scored_samples.append((sample, completeness_score, total_score))\n",
    "    \n",
    "    # Sort by score and select top samples\n",
    "    scored_samples.sort(key=lambda x: x[2], reverse=True)\n",
    "    selected_samples = [item[0] for item in scored_samples[:target_size]]\n",
    "    \n",
    "    # Analysis\n",
    "    field_counts = [item[1] for item in scored_samples[:target_size]]\n",
    "    avg_fields = sum(field_counts) / len(field_counts)\n",
    "    complete_samples = sum(1 for count in field_counts if count == 14)\n",
    "    \n",
    "    print(f\"Subset Analysis:\")\n",
    "    print(f\"Selected: {len(selected_samples):,} samples\")\n",
    "    print(f\"Average fields per sample: {avg_fields:.1f}/14\")\n",
    "    print(f\"Samples with all 14 fields: {complete_samples:,}\")\n",
    "    print(f\"Samples with ≥10 fields: {sum(1 for c in field_counts if c >= 10):,}\")\n",
    "    \n",
    "    return selected_samples\n",
    "\n",
    "def export_curated_dataset(samples):\n",
    "    \n",
    "    print(f\"\\nExporting {len(samples):,} samples to clean JSONL format\")\n",
    "    \n",
    "    # Convert to export format\n",
    "    export_data = []\n",
    "    for i, sample in enumerate(samples):\n",
    "        clean_extraction = {}\n",
    "        for field in TARGET_FIELDS:\n",
    "            clean_extraction[field] = sample['extraction'].get(field, \"unknown\")\n",
    "        \n",
    "        export_entry = {\n",
    "            \"instruction\": f\"Extract relevant information from this conflict event report:\\n\\n{sample['note']}\",\n",
    "            \"output\": json.dumps(clean_extraction, ensure_ascii=False),\n",
    "            \"id\": f\"acled_{i+1:05d}\",\n",
    "            \"fields_extracted\": len([v for v in clean_extraction.values() if v != \"unknown\"])\n",
    "        }\n",
    "        export_data.append(export_entry)\n",
    "    \n",
    "    dataset_path = os.path.join(export_dir, \"ACLED_finetuning_dataset.jsonl\")\n",
    "    with open(dataset_path, 'w', encoding='utf-8') as f:\n",
    "        for entry in export_data:\n",
    "            f.write(json.dumps(entry, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    field_counts = [e['fields_extracted'] for e in export_data]\n",
    "    country_dist = defaultdict(int)\n",
    "    for sample in samples:\n",
    "        country = sample['extraction'].get('country', sample['metadata']['source_country'])\n",
    "        country_dist[country] += 1\n",
    "    \n",
    "    metadata = {\n",
    "        'dataset_info': {\n",
    "            'creation_date': datetime.now().isoformat(),\n",
    "            'total_samples': len(export_data),\n",
    "            'source': 'ACLED Processing Pipeline',\n",
    "            'target_fields': TARGET_FIELDS,\n",
    "            'geographic_scope': TARGET_COUNTRIES\n",
    "        },\n",
    "        'quality_statistics': {\n",
    "            'average_fields_per_sample': sum(field_counts) / len(field_counts),\n",
    "            'samples_with_all_14_fields': sum(1 for c in field_counts if c == 14),\n",
    "            'samples_with_10_plus_fields': sum(1 for c in field_counts if c >= 10)\n",
    "        },\n",
    "        'field_coverage': {\n",
    "            field: {\n",
    "                'count': sum(1 for s in samples if s['extraction'].get(field) != \"unknown\"),\n",
    "                'percentage': (sum(1 for s in samples if s['extraction'].get(field) != \"unknown\") / len(samples)) * 100,\n",
    "                'examples': list(set([str(s['extraction'].get(field)) for s in samples \n",
    "                                    if s['extraction'].get(field) != \"unknown\"]))[:10]\n",
    "            }\n",
    "            for field in TARGET_FIELDS\n",
    "        },\n",
    "        'geographic_distribution': dict(country_dist)\n",
    "    }\n",
    "    \n",
    "    metadata_path = os.path.join(export_dir, \"dataset_metadata.json\")\n",
    "    with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"Dataset exported: {dataset_path}\")\n",
    "    print(f\"Metadata exported: {metadata_path}\")\n",
    "    \n",
    "    return export_data, metadata\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STRATEGIC SUBSET CREATION & EXPORT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "strategic_samples = strategic_subset(valid_samples, target_size=25000)\n",
    "export_data, metadata = export_curated_dataset(strategic_samples)\n",
    "\n",
    "print(f\"\\nValidation Summary:\")\n",
    "print(f\"Total samples: {len(export_data):,}\")\n",
    "print(f\"Average fields per sample: {sum(e['fields_extracted'] for e in export_data) / len(export_data):.1f}/14\")\n",
    "print(f\"Export directory: {export_dir}\")\n",
    "print(f\"Files created: ACLED_finetuning_dataset.jsonl, dataset_metadata.json\")\n",
    "\n",
    "# ACLED sample taken from the curated dataset\n",
    "if export_data:\n",
    "    sample = export_data[0]\n",
    "    print(f\"\\nSample entry:\")\n",
    "    print(f\"ID: {sample['id']}\")\n",
    "    print(f\"Fields extracted: {sample['fields_extracted']}\")\n",
    "    print(f\"Instruction: {sample['instruction'][:100]}\")\n",
    "    \n",
    "    parsed_output = json.loads(sample['output'])\n",
    "    print(f\"Output preview:\")\n",
    "    for field, value in list(parsed_output.items())[:5]:\n",
    "        if value != \"unknown\":\n",
    "            print(f\"  {field}: {value}\")\n",
    "\n",
    "print(f\"\\nExport complete. Dataset ready for fine-tuning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset Creation\n",
    "\n",
    "To support evaluation of the fine-tuned model, a 400-sample test dataset was curated from the ACLED records dated between 2022 and 2024. The function `create_acled_test_dataset()` performs the following:\n",
    "\n",
    "- **Filtering**: Limits the dataset to recent events (post-2022), falling back to the full dataset if none are found.\n",
    "- **Proportional Sampling**: Ensures geographic diversity by allocating samples proportionally across countries based on their representation in the filtered data.\n",
    "- **Balancing**: Adjusts the number of samples per country to match the target size without over-representing any one country.\n",
    "- **Fallback Filling**: If underfilled, the function samples additional entries to meet the specified size.\n",
    "- **Output**: The resulting 400 test samples (text-only `notes` field) are saved to `ACLED_test_dataset.csv`.\n",
    "\n",
    "This balanced and recent test set provides a representative evaluation benchmark for structured event extraction performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 400-sample ACLED test dataset\n",
      "Saved to: ACLED_data_export/ACLED_test_dataset.csv\n",
      "\n",
      "Sample entries:\n",
      "   On 6 November 2023, Russian forces shelled Ukrainian military positions in Hulia\n",
      "   On 8 January 2025, Russian forces carried out airstrikes and shelled Dudchany, K\n",
      "   Defusal: On 15 March 2024, Russian air forces bombed Selydove, Donetsk. The bomb\n"
     ]
    }
   ],
   "source": [
    "def create_acled_test_dataset(df, size=400):\n",
    "    \"\"\"200 test samples from ACLED data (2022-2024), focusing on geographic diversity.\"\"\"\n",
    "\n",
    "    df_filtered = df[df['event_date'] >= '2022-01-01'].copy()\n",
    "\n",
    "    if len(df_filtered) == 0:\n",
    "        print(\"No data available for 2022-2024 period, using full dataset.\")\n",
    "        df_filtered = df.copy()\n",
    "    if len(df_filtered) < size:\n",
    "        print(f\"Only {len(df_filtered)} samples available — using all available data.\")\n",
    "        size = len(df_filtered)\n",
    "\n",
    "    test_samples = []\n",
    "\n",
    "    # Proportional allocation of samples across countries\n",
    "    countries = df_filtered['country'].value_counts()\n",
    "    samples_per_country = {}\n",
    "\n",
    "    for country in countries.index:\n",
    "        proportion = countries[country] / len(df_filtered)\n",
    "        allocated = max(1, int(size * proportion))\n",
    "        samples_per_country[country] = min(allocated, countries[country])\n",
    "\n",
    "    # Adjust allocations if they exceed total desired size\n",
    "    total_allocated = sum(samples_per_country.values())\n",
    "    if total_allocated > size:\n",
    "        scale_factor = size / total_allocated\n",
    "        for country in samples_per_country:\n",
    "            samples_per_country[country] = max(1, int(samples_per_country[country] * scale_factor))\n",
    "\n",
    "    # Sampling from each country\n",
    "    for country, count in samples_per_country.items():\n",
    "        country_data = df_filtered[df_filtered['country'] == country]\n",
    "        sampled = country_data.sample(n=count, random_state=42) if len(country_data) >= count else country_data\n",
    "\n",
    "        for _, row in sampled.iterrows():\n",
    "            if len(test_samples) >= size:\n",
    "                break\n",
    "            test_samples.append({'notes': row['notes']})\n",
    "\n",
    "    # Fill remaining slots if needed\n",
    "    remaining = size - len(test_samples)\n",
    "    if remaining > 0:\n",
    "        remaining_data = df_filtered[~df_filtered.index.isin(df_filtered.index[:len(test_samples)])]\n",
    "        additional = remaining_data.sample(n=min(remaining, len(remaining_data)), random_state=42)\n",
    "        for _, row in additional.iterrows():\n",
    "            test_samples.append({'notes': row['notes']})\n",
    "\n",
    "    return test_samples[:size]\n",
    "\n",
    "test_dataset = create_acled_test_dataset(df, size=400)\n",
    "\n",
    "test_df = pd.DataFrame(test_dataset)\n",
    "test_file_path = os.path.join(export_dir, \"ACLED_test_dataset.csv\")\n",
    "test_df.to_csv(test_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Created {len(test_dataset)}-sample ACLED test dataset\")\n",
    "print(f\"Saved to: {test_file_path}\")\n",
    "\n",
    "print(\"\\nSample entries:\")\n",
    "for i in range(min(3, len(test_dataset))):\n",
    "    print(f\"   {test_dataset[i]['notes'][:80]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
